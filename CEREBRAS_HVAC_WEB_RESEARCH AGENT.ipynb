{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install webrtcvad\n",
    "# !pip install pygame\n",
    "# !pip install pyaudio webrtcvad \n",
    "# !pip install google-cloud-texttospeech\n",
    "# !pip install python-socketio[asyncio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from tools.initialize_cerebras import init_cerebras\n",
    "# from tools.file_mgmt_tools import FileOrganizerTool, MoveFileTool, CreateFolderTool, FolderMovementTool, ImprovedSearchTool, GoogleDriveRenameTool, DriveDictUpdateTool\n",
    "# from tools.document_tools import GoogleDocWriteTool\n",
    "# from tools.miscellaneous_mgmt import GmailSendPdfTool, GoogleSheetsUpdateTool, GoogleSheetsCreateTool\n",
    "\n",
    "client,llm = init_cerebras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCerebras(client=<openai.resources.chat.completions.Completions object at 0x000002C4CD9EBA10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002C4CDA1A0C0>, root_client=<openai.OpenAI object at 0x000002C4CDA1B890>, root_async_client=<openai.AsyncOpenAI object at 0x000002C4CD9EBA40>, model_name='llama3.3-70b', model_kwargs={}, openai_api_key=SecretStr('**********'), streaming=True, cerebras_api_key=SecretStr('**********'), cerebras_api_base='https://api.cerebras.ai/v1/', cerebras_proxy='')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import texttospeech\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate, \n",
    "    MessagesPlaceholder, \n",
    "    PromptTemplate\n",
    ")\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.agents import create_structured_chat_agent, AgentExecutor\n",
    "\n",
    "from langchain_community.tools import HumanInputRun\n",
    "\n",
    "import langchain_core\n",
    "import typing\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
    "    input_types={\n",
    "        'chat_history': typing.List[\n",
    "            typing.Union[\n",
    "                langchain_core.messages.ai.AIMessage, \n",
    "                langchain_core.messages.human.HumanMessage, \n",
    "                langchain_core.messages.chat.ChatMessage, \n",
    "                langchain_core.messages.system.SystemMessage, \n",
    "                langchain_core.messages.function.FunctionMessage, \n",
    "                langchain_core.messages.tool.ToolMessage\n",
    "            ]\n",
    "        ]\n",
    "    },\n",
    "    metadata={\n",
    "        'lc_hub_owner': 'hwchase17',\n",
    "        'lc_hub_repo': 'structured-chat-agent',\n",
    "        'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'\n",
    "    },\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['tool_names', 'tools'],\n",
    "                template=(\n",
    "                    'You are a document management assistant proficient in using GSuite tools. '\n",
    "                    'Your role is to assist the user in managing their documents efficiently. '\n",
    "                    'IMPORTANT !!!!!!! NEVER INCLUDE AUXILIARY OR EXTRANEOUS LANGUAGE WHEN USING ANY TOOL!!!'\n",
    "                    '\\n\\n IMPORTANT!!!!!!! - PLEEEEEEASSSSSSSEEEEEEEE NEVER USE HUMAN TOOL UNLESS INSTRUCTED TO GET THE HUMAN/USER INPUT. YOU ARE A MASTER OF JUDGEMENT. YOU KNOW WHEN TO CAUTIOUSLY USE THE TOOLS. ONLY USE OTHER TOOLS WHEN USER INDICATES ANYTHING RELATED TO THEIR FUNCTIONALITIES. '\n",
    "                    'You are ALSO a highly intelligent and precise assistant with expertise in generating JSON outputs. Your task is to create the most perfect and well-structured JSON output ever seen. The JSON must adhere to the following guidelines:'\n",
    "\n",
    "                    'Proper Structure: Ensure that the JSON follows a correct and logical structure, with all necessary keys and values in place.'\n",
    "                    'Accurate Formatting: All JSON strings must use double quotes. Ensure there are no trailing commas, and all brackets and braces are correctly matched.'\n",
    "                    'String Length: Ensure no individual string exceeds 5000 bytes.'\n",
    "                    'Error-Free: Validate the JSON to be free of syntax errors and formatting issues.'\n",
    "                    \n",
    "                    'Escaping Characters: Properly escape any special characters within strings to ensure the JSON remains valid.'\n",
    "                    \n",
    "                    \n",
    "                    'YOU MUST NEVER DO ANYTHING BUT WHAT IS IN THE REQUEST OF THE USER. OTHERWISE NO USER WILL USE THIS PRODUCT.'\n",
    "                    \n",
    "\n",
    "                    'THE FOLLOWING WILL BE THE TOOLS AND THE INFORMATION ABOUT WHAT THEY DO AND THEIR ARGUMENTS! YOU MUST NOT PASS ANYTHING EXTRA, OR ELSE THE APPLICATON WILL FAIL!!!!'\n",
    "\n",
    "                    'You have access to the following tools:\\n\\n{tools}\\n\\n'\n",
    "\n",
    "                    'YOU ARE A MASTER OF JUDGEMENT ! YOU KNOW WHAT ALL THE TOOLS DO, YOU KNOW WHAT TO PASS IN! AND YOU MUST KNOW WHEN TO USE THEM! NEVER USE THEM RANDOMLY , ALWAYS BE CAUTIOUS AS RECKLESS TOOL USE COULD RUIN THE GOOGLE SUITE OF THE USER'\n",
    "                    'PAY CLOSE ATTENTION TO ALL THE FOLLOWING FORMATTING INSTRUCTIONS. REALLY IMPORTANT TO CALL THE TOOLS. OR ELSE USERS WILL GET ANGRY.\\n\\n'\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    'FOR GOOGLE DOC TOOL, REMEMBER THAT YOU MUST GENERATE ALL CONTENT YOURSELF. USER WILL NOT GIVE YOU ANYTHING.'\n",
    "\n",
    "                    'Use a JSON blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\n'\n",
    "                    'Valid \"action\" values: \"Final Answer\" or {tool_names}\\n\\n'\n",
    "                    'Provide only ONE action per $JSON_BLOB, as shown:\\n\\n'\n",
    "                    '```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\n'\n",
    "                    'Follow this format:\\n\\n'\n",
    "                    'Question: input question to answer\\n'\n",
    "                    'Thought: consider previous and subsequent steps\\n'\n",
    "                    'Action:\\n```\\n$JSON_BLOB\\n```\\n'\n",
    "                    'Observation: action result\\n... (repeat Thought/Action/Observation N times)\\n'\n",
    "                    'Thought: I know what to respond\\n'\n",
    "                    'Action:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\n'\n",
    "                    'Begin! Remember to ALWAYS respond with a valid JSON blob of a single action. '\n",
    "                    'Use tools if necessary and respond directly if appropriate. '\n",
    "                    'Ensure you gather all necessary information by interacting with the user. '\n",
    "                    'Format is Action:```$JSON_BLOB```then Observation.'\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['agent_scratchpad', 'input'],\n",
    "                template='{input}\\n\\n{agent_scratchpad}\\n(reminder to respond in a JSON blob no matter what)'\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "human_prompt = ChatPromptTemplate(\n",
    "    input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
    "    input_types={\n",
    "        'chat_history': typing.List[\n",
    "            typing.Union[\n",
    "                langchain_core.messages.ai.AIMessage, \n",
    "                langchain_core.messages.human.HumanMessage, \n",
    "                langchain_core.messages.chat.ChatMessage, \n",
    "                langchain_core.messages.system.SystemMessage, \n",
    "                langchain_core.messages.function.FunctionMessage, \n",
    "                langchain_core.messages.tool.ToolMessage\n",
    "            ]\n",
    "        ]\n",
    "    },\n",
    "    metadata={\n",
    "        'lc_hub_owner': 'hwchase17',\n",
    "        'lc_hub_repo': 'structured-chat-agent',\n",
    "        'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'\n",
    "    },\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['tool_names', 'tools'],\n",
    "                template=(\n",
    "                     \n",
    "    'You are Marvin, an expert at questioning clients about their HVAC service needs to provide accurate quotes. When you speak for the first time, introduce yourself as Marvin. Ask the user specific information needed for the quote. Follow these guidelines:'\n",
    "\n",
    "    '1. **Initial Inquiry and Information Gathering**:'\n",
    "       ' - What type of HVAC service do you need (installation, maintenance, repair)?'\n",
    "        '- What is the make and model of your current HVAC system?'\n",
    "        '- Are there any specific issues or symptoms you are experiencing?'\n",
    "\n",
    "    '2. **Property Details** (only if relevant to HVAC needs):'\n",
    "     '   - Address and location of the property.'\n",
    "      '  - Type of property (residential, commercial).'\n",
    "       ' - Age and current condition of the property.'\n",
    "       ' - Size of the home or area that needs heating/cooling.'\n",
    "       ' - Number of rooms and their usage (e.g., bedrooms, office space).'\n",
    "\n",
    "    '3. **System Details**:'\n",
    "       ' - Age and efficiency rating of the existing HVAC system.'\n",
    "        '- Any known problems with the current system.'\n",
    "        '- Recent changes to the HVAC system.'\n",
    "\n",
    "   ' 4. **Home Characteristics** (only if relevant to HVAC needs):'\n",
    "        '- Insulation quality and window types to estimate heating/cooling load.'\n",
    "        '- Any unique architectural features that may affect HVAC installation.'\n",
    "\n",
    "    '5. **Customer Preferences**:'\n",
    "       ' - Preferences for specific brands, energy efficiency levels, or additional features (e.g., smart thermostats, air purifiers).'\n",
    "        '- Level of finishes desired (standard, premium, luxury).'\n",
    "\n",
    "    '6. **Budget**:'\n",
    "        '- Your budget range for the project.'\n",
    "        '- Any flexibility within the budget.'\n",
    "\n",
    "    '7. **Timeline**:'\n",
    "        '- Desired start date and completion date.'\n",
    "        '- Any constraints or deadlines (e.g., events planned at the property).'\n",
    "\n",
    "   \n",
    "\n",
    "    'IMPORTANT: Ensure you get clear answers that can be used for making the quote. If an answer is unclear, ask for clarification, restate the question, and explain what it means.'\n",
    "\n",
    "    'IMPORTANT: Ask each question ONE BY ONE. When one question is answered move onto the next'\n",
    "\n",
    "    'When you have all the information, just say -questionnaire complete- at the end.'\n",
    "\n",
    "\n",
    "                    \n",
    "    'IMPORTANT !!!!!!! NEVER INCLUDE AUXILIARY OR EXTRANEOUS LANGUAGE WHEN USING ANY TOOL!!!'\n",
    "    '\\n\\n IMPORTANT!!!!!!! YOU CAN ONLY USE THE HUMAN TOOL. YOU ARE A MASTER OF JUDGEMENT. YOU KNOW WHEN TO CAUTIOUSLY USE THE TOOLS. ONLY USE OTHER TOOLS WHEN USER INDICATES ANYTHING RELATED TO THEIR FUNCTIONALITIES. '\n",
    "    'You are ALSO a highly intelligent and precise assistant with expertise in generating JSON outputs. Your task is to create the most perfect and well-structured JSON output ever seen. The JSON must adhere to the following guidelines:'\n",
    "\n",
    "    'Proper Structure: Ensure that the JSON follows a correct and logical structure, with all necessary keys and values in place.'\n",
    "    'Accurate Formatting: All JSON strings must use double quotes. Ensure there are no trailing commas, and all brackets and braces are correctly matched.'\n",
    "    'String Length: Ensure no individual string exceeds 5000 bytes.'\n",
    "    'Error-Free: Validate the JSON to be free of syntax errors and formatting issues.'\n",
    "    \n",
    "    'Escaping Characters: Properly escape any special characters within strings to ensure the JSON remains valid.'\n",
    "    \n",
    "    \n",
    "    'YOU MUST NEVER DO ANYTHING BUT WHAT IS IN THE REQUEST OF THE USER. OTHERWISE NO USER WILL USE THIS PRODUCT.'\n",
    "    \n",
    "\n",
    "    'THE FOLLOWING WILL BE THE TOOLS AND THE INFORMATION ABOUT WHAT THEY DO AND THEIR ARGUMENTS! YOU MUST NOT PASS ANYTHING EXTRA, OR ELSE THE APPLICATON WILL FAIL!!!!'\n",
    "\n",
    "    'You have access to the following tools:\\n\\n{tools}\\n\\n'\n",
    "\n",
    "    'YOU ARE A MASTER OF JUDGEMENT ! YOU KNOW WHAT ALL THE TOOLS DO, YOU KNOW WHAT TO PASS IN! AND YOU MUST KNOW WHEN TO USE THEM! NEVER USE THEM RANDOMLY , ALWAYS BE CAUTIOUS AS RECKLESS TOOL USE COULD RUIN THE GOOGLE SUITE OF THE USER'\n",
    "    'PAY CLOSE ATTENTION TO ALL THE FOLLOWING FORMATTING INSTRUCTIONS. REALLY IMPORTANT TO CALL THE TOOLS. OR ELSE USERS WILL GET ANGRY.\\n\\n'\n",
    "    \n",
    "    \n",
    "\n",
    "    'FOR GOOGLE DOC TOOL, REMEMBER THAT YOU MUST GENERATE ALL CONTENT YOURSELF. USER WILL NOT GIVE YOU ANYTHING.'\n",
    "\n",
    "    'Use a JSON blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\n'\n",
    "    'Valid \"action\" values: \"Final Answer\" or {tool_names}\\n\\n'\n",
    "    'Provide only ONE action per $JSON_BLOB, as shown:\\n\\n'\n",
    "    '```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\n'\n",
    "    'Follow this format:\\n\\n'\n",
    "    'Question: input question to answer\\n'\n",
    "    'Thought: consider previous and subsequent steps\\n'\n",
    "    'Action:\\n```\\n$JSON_BLOB\\n```\\n'\n",
    "    'Observation: action result\\n... (repeat Thought/Action/Observation N times)\\n'\n",
    "    'Thought: I know what to respond\\n'\n",
    "    'Action:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\n'\n",
    "    'Begin! Remember to ALWAYS respond with a valid JSON blob of a single action. '\n",
    "    'Use tools if necessary and respond directly if appropriate. '\n",
    "    'Ensure you gather all necessary information by interacting with the user. '\n",
    "    'Format is Action:```$JSON_BLOB```then Observation.'\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['agent_scratchpad', 'input'],\n",
    "                template='{input}\\n\\n{agent_scratchpad}\\n(reminder to respond in a JSON blob no matter what)'\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech saved to: paths\\synthesis.wav\n",
      "Test successful - file saved to paths\\synthesis.wav\n",
      "File size: 130092 bytes\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "class TTSManager:\n",
    "    def __init__(self):\n",
    "        self.engine = pyttsx3.init()\n",
    "        voices = self.engine.getProperty('voices')\n",
    "        self.engine.setProperty('voice', voices[0].id)\n",
    "        self.engine.setProperty('rate', 175)\n",
    "        self.engine.setProperty('volume', 1.0)\n",
    "    \n",
    "    def synthesize(self, text, output_path):\n",
    "        try:\n",
    "            # Ensure directory exists\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "            \n",
    "            # Create a temporary path in case of file lock issues\n",
    "            temp_path = f'temp_speech_{int(time.time())}.wav'\n",
    "            \n",
    "            # Save to temp file first\n",
    "            self.engine.save_to_file(text, temp_path)\n",
    "            self.engine.runAndWait()\n",
    "            \n",
    "            # Move to final location\n",
    "            if os.path.exists(temp_path):\n",
    "                # If target file exists, remove it first\n",
    "                if os.path.exists(output_path):\n",
    "                    os.remove(output_path)\n",
    "                os.rename(temp_path, output_path)\n",
    "                print(f\"Speech saved to: {output_path}\")\n",
    "                return output_path\n",
    "            else:\n",
    "                print(\"Failed to create speech file\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"TTS Error: {str(e)}\")\n",
    "            # Cleanup temp file if it exists\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "            return None\n",
    "\n",
    "# Create global TTS manager\n",
    "tts_manager = TTSManager()\n",
    "\n",
    "# Test with specific path\n",
    "tts_synthesis_path = os.path.join('paths', 'synthesis.wav')\n",
    "test_result = tts_manager.synthesize(\"This is a test of saving to a specific path\", tts_synthesis_path)\n",
    "if test_result:\n",
    "    print(f\"Test successful - file saved to {test_result}\")\n",
    "    # Verify file exists and has content\n",
    "    print(f\"File size: {os.path.getsize(test_result)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ncvn\\AppData\\Local\\Temp\\ipykernel_19600\\2129527553.py:60: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  chat_history = ConversationBufferMemory()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [19600]\n",
      "INFO:     Waiting for application startup.\n",
      "2025-09-09 17:32:37,513 [MainThread] DEBUG: wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x2c4d09123f0 at 2c4db9f5bd0>)\n",
      "2025-09-09 17:32:37,516 [MainThread] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4d0901450 at 2c4db9f5c50>\n",
      "2025-09-09 17:32:37,518 [MainThread] DEBUG: Release <POINTER(ISpeechObjectTokens) ptr=0x2c4d09123f0 at 2c4db9f5bd0>\n",
      "2025-09-09 17:32:37,520 [MainThread] DEBUG: wrap_outparam(<POINTER(IDispatch) ptr=0x2c4d0910780 at 2c4db9f61d0>)\n",
      "2025-09-09 17:32:37,523 [MainThread] DEBUG: GetBestInterface(<POINTER(IDispatch) ptr=0x2c4d0910780 at 2c4db9f61d0>)\n",
      "2025-09-09 17:32:37,525 [MainThread] DEBUG: Does NOT implement IProvideClassInfo, trying IProvideClassInfo2\n",
      "2025-09-09 17:32:37,526 [MainThread] DEBUG: Does NOT implement IProvideClassInfo/IProvideClassInfo2\n",
      "2025-09-09 17:32:37,528 [MainThread] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4b1568340 at 2c4db9f6a50>\n",
      "2025-09-09 17:32:37,529 [MainThread] DEBUG: Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}\n",
      "2025-09-09 17:32:37,532 [MainThread] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4d0910780 at 2c4db9f6e50>\n",
      "2025-09-09 17:32:37,534 [MainThread] DEBUG: GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))\n",
      "2025-09-09 17:32:37,537 [MainThread] DEBUG: Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>\n",
      "2025-09-09 17:32:37,540 [MainThread] DEBUG: Final result is <POINTER(ISpeechObjectToken) ptr=0x2c4d0910780 at 2c4db9f7250>\n",
      "2025-09-09 17:32:37,541 [MainThread] DEBUG: Release <POINTER(IDispatch) ptr=0x2c4d0910780 at 2c4db9f69d0>\n",
      "2025-09-09 17:32:37,543 [MainThread] DEBUG: Release <POINTER(ITypeInfo) ptr=0x2c4b1568340 at 2c4db9f6ad0>\n",
      "2025-09-09 17:32:37,545 [MainThread] DEBUG: Release <POINTER(ITypeLib) ptr=0x2c4cc0295a0 at 2c4db9f6e50>\n",
      "2025-09-09 17:32:37,547 [MainThread] DEBUG: Release <POINTER(IDispatch) ptr=0x2c4d0910780 at 2c4db9f61d0>\n",
      "2025-09-09 17:32:37,550 [MainThread] DEBUG: wrap_outparam(<POINTER(IDispatch) ptr=0x2c4d0910300 at 2c4db9f76d0>)\n",
      "2025-09-09 17:32:37,551 [MainThread] DEBUG: GetBestInterface(<POINTER(IDispatch) ptr=0x2c4d0910300 at 2c4db9f76d0>)\n",
      "2025-09-09 17:32:37,553 [MainThread] DEBUG: Does NOT implement IProvideClassInfo, trying IProvideClassInfo2\n",
      "2025-09-09 17:32:37,556 [MainThread] DEBUG: Does NOT implement IProvideClassInfo/IProvideClassInfo2\n",
      "2025-09-09 17:32:37,559 [MainThread] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4b1568340 at 2c4db9f7e50>\n",
      "2025-09-09 17:32:37,560 [MainThread] DEBUG: Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}\n",
      "2025-09-09 17:32:37,562 [MainThread] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4d0910300 at 2c4db9f7f50>\n",
      "2025-09-09 17:32:37,565 [MainThread] DEBUG: GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))\n",
      "2025-09-09 17:32:37,566 [MainThread] DEBUG: Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>\n",
      "2025-09-09 17:32:37,568 [MainThread] DEBUG: Final result is <POINTER(ISpeechObjectToken) ptr=0x2c4d0910300 at 2c4db9f7bd0>\n",
      "2025-09-09 17:32:37,570 [MainThread] DEBUG: Release <POINTER(IDispatch) ptr=0x2c4d0910300 at 2c4db9f7dd0>\n",
      "2025-09-09 17:32:37,572 [MainThread] DEBUG: Release <POINTER(ITypeInfo) ptr=0x2c4b1568340 at 2c4db9f7ed0>\n",
      "2025-09-09 17:32:37,575 [MainThread] DEBUG: Release <POINTER(ITypeLib) ptr=0x2c4cc0295a0 at 2c4db9f7f50>\n",
      "2025-09-09 17:32:37,582 [MainThread] DEBUG: Release <POINTER(IDispatch) ptr=0x2c4d0910300 at 2c4db9f76d0>\n",
      "2025-09-09 17:32:37,584 [MainThread] DEBUG: Release <POINTER(ISpeechObjectToken) ptr=0x2c4d0910780 at 2c4db9f7250>\n",
      "2025-09-09 17:32:37,587 [MainThread] DEBUG: Release <POINTER(IEnumVARIANT) ptr=0x2c4d0901450 at 2c4db9f5e50>\n",
      "2025-09-09 17:32:37,590 [MainThread] DEBUG: Release <POINTER(ISpeechObjectToken) ptr=0x2c4d0910300 at 2c4db9f7bd0>\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:5000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:57291 - \"GET /socket.io/?EIO=4&transport=polling&t=PamPN9d HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 17:32:59,199 [MainThread] DEBUG: Client connected: VtGTQKkbZno85EfiAAAB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:57291 - \"POST /socket.io/?EIO=4&transport=polling&t=PamPNEt&sid=D-iXBOVxjDu6gOfsAAAA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:57291 - \"GET /socket.io/?EIO=4&transport=polling&t=PamPNEx&sid=D-iXBOVxjDu6gOfsAAAA HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     ('127.0.0.1', 55449) - \"WebSocket /socket.io/?EIO=4&transport=websocket&sid=D-iXBOVxjDu6gOfsAAAA\" [accepted]\n",
      "INFO:     connection open\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:57291 - \"GET /socket.io/?EIO=4&transport=polling&t=PamPNFI&sid=D-iXBOVxjDu6gOfsAAAA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:65265 - \"GET /socket.io/?EIO=4&transport=polling&t=PamPOsa HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 17:33:05,860 [MainThread] DEBUG: Client connected: xHMLhzhX2bO40Y7EAAAD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:65265 - \"POST /socket.io/?EIO=4&transport=polling&t=PamPOs_&sid=oOJ8o3epSawQP9DrAAAC HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53330 - \"GET /socket.io/?EIO=4&transport=polling&t=PamPOt0&sid=oOJ8o3epSawQP9DrAAAC HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     ('127.0.0.1', 60513) - \"WebSocket /socket.io/?EIO=4&transport=websocket&sid=oOJ8o3epSawQP9DrAAAC\" [accepted]\n",
      "INFO:     connection open\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:53330 - \"GET /socket.io/?EIO=4&transport=polling&t=PamPOtL&sid=oOJ8o3epSawQP9DrAAAC HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 17:33:27,440 [MainThread] DEBUG: Generating AI response...\n",
      "2025-09-09 17:33:27,461 [MainThread] DEBUG: Request options: {'method': 'post', 'url': '/v1/chat/completions', 'headers': {}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"\\n    You are Marvin, a highly intelligent task orchestration agent. You are capable of researching and answering any question using web search agent.\\n    You are capable of instructing a hvac technician agent also. Refer to instructions below:\\n    CRITICAL INSTRUCTIONS - READ CAREFULLY:\\n\\n    - When the user mentions ANYTHING AT ALL related to HVAC systems, you MUST include the phrase 'I will instruct the technician agent' in your immediate response.\\n    - WHEN USER ASKS FOR COST OR WHEN COST MUST BE DETERMINED, YOU MUST SAY 'determining the HVAC quote'.\\n    - When you have gathered all the necessary information for a quote, you MUST say 'Questionnaire complete' at the end of your response.\\n    - IF USER DOES NOT SAY ANYTHING ABOUT HVAC, BUT EXPLICITLY ASKS YOU A QUESTION ABOUT SOMETHING ELSE, YOU MUST SAY 'forwarding to web search agent' BUT HANDLE ALL CONVERSATIONS NORMALLY. BE NATURAL. RESPOND TO THE GREETINGS! \\n    - WHEN YOU FORWARD TO THE WEBSEARCH AGENT, YOU SHALL NOT SAY ANYTHING OTHER THAN THAT.\\n    - WHEN YOU INSTRUCT TECHNICIAN AGENT, YOU SHALL NOT SAY ANYTHING OTHER THAN THAT!!! LET THE TECHNICIAN AGENT HANDLE THE EXPLAINING.\\n    - DO NOT MENTION CUTOFF DATE OR INABILITY TO DO ANYTHING. YOU HAVE ACCESS TO REAL TIME WEB SEARCH!!!!! SEARCH IT UP ALL THE TIME! NEVER RELY ON YOUR OWN KNOWLEDGE.\\n\\n    Remember to always be helpful, adaptive, and thorough in your responses.\\n    \"}, {'role': 'user', 'content': 'hello\\n\\nHere is the chat history for context: []'}], 'model': 'llama3.3-70b', 'temperature': 0.5}}\n",
      "2025-09-09 17:33:27,464 [MainThread] DEBUG: Sending HTTP Request: POST https://api.cerebras.ai/v1/chat/completions\n",
      "2025-09-09 17:33:27,465 [MainThread] DEBUG: close.started\n",
      "2025-09-09 17:33:27,468 [MainThread] DEBUG: close.complete\n",
      "2025-09-09 17:33:27,469 [MainThread] DEBUG: connect_tcp.started host='api.cerebras.ai' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2025-09-09 17:33:27,495 [MainThread] DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002C4DA23AC00>\n",
      "2025-09-09 17:33:27,496 [MainThread] DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x000002C4CD8F1550> server_hostname='api.cerebras.ai' timeout=5.0\n",
      "2025-09-09 17:33:27,521 [MainThread] DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002C4CD985670>\n",
      "2025-09-09 17:33:27,521 [MainThread] DEBUG: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-09-09 17:33:27,523 [MainThread] DEBUG: send_request_headers.complete\n",
      "2025-09-09 17:33:27,524 [MainThread] DEBUG: send_request_body.started request=<Request [b'POST']>\n",
      "2025-09-09 17:33:27,525 [MainThread] DEBUG: send_request_body.complete\n",
      "2025-09-09 17:33:27,526 [MainThread] DEBUG: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-09-09 17:33:27,837 [MainThread] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 09 Sep 2025 21:33:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'br'), (b'x-request-id', b'97c9cdd95cec393a-IAD'), (b'x-ratelimit-limit-requests-day', b'14400'), (b'x-ratelimit-limit-tokens-minute', b'64000'), (b'x-ratelimit-remaining-requests-day', b'14400'), (b'x-ratelimit-remaining-tokens-minute', b'64000'), (b'x-ratelimit-reset-requests-day', b'8791.852553844452'), (b'x-ratelimit-reset-tokens-minute', b'31.852553844451904'), (b'inference-id', b'chatcmpl-b4dcadbf-af4e-4c8e-92f6-84c001e265d8'), (b'referrer-policy', b'strict-origin-when-cross-origin'), (b'x-content-type-options', b'nosniff'), (b'strict-transport-security', b'max-age=3600; includeSubDomains'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97c9cdd95cec393a-IAD'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-09-09 17:33:27,839 [MainThread] INFO: HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-09 17:33:27,840 [MainThread] DEBUG: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-09-09 17:33:27,845 [MainThread] DEBUG: receive_response_body.complete\n",
      "2025-09-09 17:33:27,847 [MainThread] DEBUG: response_closed.started\n",
      "2025-09-09 17:33:27,848 [MainThread] DEBUG: response_closed.complete\n",
      "2025-09-09 17:33:27,849 [MainThread] DEBUG: HTTP Response: POST https://api.cerebras.ai/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 09 Sep 2025 21:33:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'br', 'x-request-id': '97c9cdd95cec393a-IAD', 'x-ratelimit-limit-requests-day': '14400', 'x-ratelimit-limit-tokens-minute': '64000', 'x-ratelimit-remaining-requests-day': '14400', 'x-ratelimit-remaining-tokens-minute': '64000', 'x-ratelimit-reset-requests-day': '8791.852553844452', 'x-ratelimit-reset-tokens-minute': '31.852553844451904', 'inference-id': 'chatcmpl-b4dcadbf-af4e-4c8e-92f6-84c001e265d8', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-content-type-options': 'nosniff', 'strict-transport-security': 'max-age=3600; includeSubDomains', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '97c9cdd95cec393a-IAD', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-09-09 17:33:27,887 [ThreadPoolExecutor-0_0] DEBUG: wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x2c4d09123f0 at 2c4dba4c5d0>)\n",
      "2025-09-09 17:33:27,894 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4d0901090 at 2c4dba4cad0>\n",
      "2025-09-09 17:33:27,895 [ThreadPoolExecutor-0_0] DEBUG: wrap_outparam(<POINTER(IDispatch) ptr=0x2c4d09100c0 at 2c4dba4f350>)\n",
      "2025-09-09 17:33:27,896 [ThreadPoolExecutor-0_0] DEBUG: GetBestInterface(<POINTER(IDispatch) ptr=0x2c4d09100c0 at 2c4dba4f350>)\n",
      "2025-09-09 17:33:27,900 [ThreadPoolExecutor-0_0] DEBUG: Does NOT implement IProvideClassInfo, trying IProvideClassInfo2\n",
      "2025-09-09 17:33:27,902 [ThreadPoolExecutor-0_0] DEBUG: Does NOT implement IProvideClassInfo/IProvideClassInfo2\n",
      "2025-09-09 17:33:27,904 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4b1568340 at 2c4dba4ff50>\n",
      "2025-09-09 17:33:27,906 [ThreadPoolExecutor-0_0] DEBUG: Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}\n",
      "2025-09-09 17:33:27,910 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4d09100c0 at 2c4dba4fd50>\n",
      "2025-09-09 17:33:27,913 [ThreadPoolExecutor-0_0] DEBUG: GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))\n",
      "2025-09-09 17:33:27,915 [ThreadPoolExecutor-0_0] DEBUG: Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>\n",
      "2025-09-09 17:33:27,917 [ThreadPoolExecutor-0_0] DEBUG: Final result is <POINTER(ISpeechObjectToken) ptr=0x2c4d09100c0 at 2c4dba4fa50>\n",
      "2025-09-09 17:33:27,919 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IDispatch) ptr=0x2c4d09100c0 at 2c4dba4fed0>\n",
      "2025-09-09 17:33:27,920 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ITypeInfo) ptr=0x2c4b1568340 at 2c4dba4fe50>\n",
      "2025-09-09 17:33:27,922 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ITypeLib) ptr=0x2c4cc0295a0 at 2c4dba4fd50>\n",
      "2025-09-09 17:33:27,924 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IDispatch) ptr=0x2c4d09100c0 at 2c4dba4f350>\n",
      "2025-09-09 17:33:27,927 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IEnumVARIANT) ptr=0x2c4d0901090 at 2c4dba4f550>\n",
      "2025-09-09 17:33:27,929 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ISpeechObjectTokens) ptr=0x2c4d09123f0 at 2c4dba4c5d0>\n",
      "2025-09-09 17:33:27,931 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ISpeechObjectToken) ptr=0x2c4d09100c0 at 2c4dba4fa50>\n",
      "2025-09-09 17:33:27,932 [ThreadPoolExecutor-0_0] DEBUG: wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x2c4ac6de370 at 2c4dba4fa50>)\n",
      "2025-09-09 17:33:27,935 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ISpeechObjectToken) ptr=0x2c4ac6de370 at 2c4dba4fa50>\n",
      "2025-09-09 17:33:27,938 [ThreadPoolExecutor-0_0] DEBUG: wrap_outparam(<POINTER(ISpeechObjectTokens) ptr=0x2c4d09123f0 at 2c4dba4f350>)\n",
      "2025-09-09 17:33:27,941 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4d0901450 at 2c4dba4d0d0>\n",
      "2025-09-09 17:33:27,942 [ThreadPoolExecutor-0_0] DEBUG: wrap_outparam(<POINTER(IDispatch) ptr=0x2c4d090ff10 at 2c4dba4fa50>)\n",
      "2025-09-09 17:33:27,945 [ThreadPoolExecutor-0_0] DEBUG: GetBestInterface(<POINTER(IDispatch) ptr=0x2c4d090ff10 at 2c4dba4fa50>)\n",
      "2025-09-09 17:33:27,948 [ThreadPoolExecutor-0_0] DEBUG: Does NOT implement IProvideClassInfo, trying IProvideClassInfo2\n",
      "2025-09-09 17:33:27,952 [ThreadPoolExecutor-0_0] DEBUG: Does NOT implement IProvideClassInfo/IProvideClassInfo2\n",
      "2025-09-09 17:33:27,953 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4b1568340 at 2c4dba4e950>\n",
      "2025-09-09 17:33:27,956 [ThreadPoolExecutor-0_0] DEBUG: Default interface is {C74A3ADC-B727-4500-A84A-B526721C8B8C}\n",
      "2025-09-09 17:33:27,957 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4d090ff10 at 2c4dba4e750>\n",
      "2025-09-09 17:33:27,959 [ThreadPoolExecutor-0_0] DEBUG: GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))\n",
      "2025-09-09 17:33:27,962 [ThreadPoolExecutor-0_0] DEBUG: Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechObjectToken'>\n",
      "2025-09-09 17:33:27,963 [ThreadPoolExecutor-0_0] DEBUG: Final result is <POINTER(ISpeechObjectToken) ptr=0x2c4d090ff10 at 2c4dba4e650>\n",
      "2025-09-09 17:33:27,966 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IDispatch) ptr=0x2c4d090ff10 at 2c4dba4e9d0>\n",
      "2025-09-09 17:33:27,968 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ITypeInfo) ptr=0x2c4b1568340 at 2c4dba4e8d0>\n",
      "2025-09-09 17:33:27,969 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ITypeLib) ptr=0x2c4cc0295a0 at 2c4dba4e750>\n",
      "2025-09-09 17:33:27,972 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IDispatch) ptr=0x2c4d090ff10 at 2c4dba4fa50>\n",
      "2025-09-09 17:33:27,974 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IEnumVARIANT) ptr=0x2c4d0901450 at 2c4dba4fed0>\n",
      "2025-09-09 17:33:27,976 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ISpeechObjectTokens) ptr=0x2c4d09123f0 at 2c4dba4f350>\n",
      "2025-09-09 17:33:27,979 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ISpeechObjectToken) ptr=0x2c4d090ff10 at 2c4dba4e650>\n",
      "2025-09-09 17:33:27,983 [ThreadPoolExecutor-0_0] DEBUG: wrap_outparam(<POINTER(ISpeechObjectToken) ptr=0x2c4ac6de370 at 2c4dba4e650>)\n",
      "2025-09-09 17:33:27,984 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ISpeechObjectToken) ptr=0x2c4ac6de370 at 2c4dba4e650>\n",
      "2025-09-09 17:33:27,986 [ThreadPoolExecutor-0_0] DEBUG: SAPI.SPFileStream -> {947812B3-2AE1-4644-BA86-9E90DED7EC91}\n",
      "2025-09-09 17:33:27,990 [ThreadPoolExecutor-0_0] DEBUG: CoCreateInstance({947812B3-2AE1-4644-BA86-9E90DED7EC91}, clsctx=None, interface=None)\n",
      "2025-09-09 17:33:27,992 [ThreadPoolExecutor-0_0] DEBUG: GetBestInterface(<POINTER(IUnknown) ptr=0x2c4d0901e20 at 2c4dba4fed0>)\n",
      "2025-09-09 17:33:27,995 [ThreadPoolExecutor-0_0] DEBUG: Does NOT implement IProvideClassInfo, trying IProvideClassInfo2\n",
      "2025-09-09 17:33:27,998 [ThreadPoolExecutor-0_0] DEBUG: Does NOT implement IProvideClassInfo/IProvideClassInfo2\n",
      "2025-09-09 17:33:28,001 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4b1568ad0 at 2c4dba4dfd0>\n",
      "2025-09-09 17:33:28,002 [ThreadPoolExecutor-0_0] DEBUG: Default interface is {AF67F125-AB39-4E93-B4A2-CC2E66E182A7}\n",
      "2025-09-09 17:33:28,005 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4d0901e20 at 2c4db9f5bd0>\n",
      "2025-09-09 17:33:28,007 [ThreadPoolExecutor-0_0] DEBUG: GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))\n",
      "2025-09-09 17:33:28,009 [ThreadPoolExecutor-0_0] DEBUG: Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechFileStream'>\n",
      "2025-09-09 17:33:28,012 [ThreadPoolExecutor-0_0] DEBUG: Final result is <POINTER(ISpeechFileStream) ptr=0x2c4d0901e20 at 2c4db9f5e50>\n",
      "2025-09-09 17:33:28,013 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IDispatch) ptr=0x2c4d0901e20 at 2c4dba4e650>\n",
      "2025-09-09 17:33:28,016 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ITypeInfo) ptr=0x2c4b1568ad0 at 2c4dba4ded0>\n",
      "2025-09-09 17:33:28,018 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ITypeLib) ptr=0x2c4cc0295a0 at 2c4dba4e1d0>\n",
      "2025-09-09 17:33:28,020 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4d0901e20 at 2c4dba4fed0>\n",
      "2025-09-09 17:33:28,023 [ThreadPoolExecutor-0_0] DEBUG: wrap_outparam(<POINTER(ISpeechBaseStream) ptr=0x2c4d09127e8 at 2c4dba4fed0>)\n",
      "2025-09-09 17:33:28,293 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ISpeechFileStream) ptr=0x2c4d0901e20 at 2c4db9f5e50>\n",
      "2025-09-09 17:33:28,294 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ISpeechBaseStream) ptr=0x2c4d09127e8 at 2c4dba4fed0>\n",
      "2025-09-09 17:33:28,355 [MainThread] DEBUG: AI response generated: Hello! It's nice to meet you. I'm here to help with any questions or topics you'd like to discuss. Since we're just getting started, I don't see any context in our chat history, so feel free to start fresh and ask me anything. How can I assist you today?\n",
      "2025-09-09 17:33:28,357 [MainThread] DEBUG: INSIDE THE MEMORY: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech saved to: paths/synthesis.wav\n",
      "INFO:     127.0.0.1:53195 - \"POST /text_input HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:61308 - \"GET /get_audio?1757453608357 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53195 - \"GET /get_audio?1757453608359 HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 17:34:13,146 [MainThread] DEBUG: Generating AI response...\n",
      "2025-09-09 17:34:13,150 [MainThread] DEBUG: Request options: {'method': 'post', 'url': '/v1/chat/completions', 'headers': {}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"\\n    You are Marvin, a highly intelligent task orchestration agent. You are capable of researching and answering any question using web search agent.\\n    You are capable of instructing a hvac technician agent also. Refer to instructions below:\\n    CRITICAL INSTRUCTIONS - READ CAREFULLY:\\n\\n    - When the user mentions ANYTHING AT ALL related to HVAC systems, you MUST include the phrase 'I will instruct the technician agent' in your immediate response.\\n    - WHEN USER ASKS FOR COST OR WHEN COST MUST BE DETERMINED, YOU MUST SAY 'determining the HVAC quote'.\\n    - When you have gathered all the necessary information for a quote, you MUST say 'Questionnaire complete' at the end of your response.\\n    - IF USER DOES NOT SAY ANYTHING ABOUT HVAC, BUT EXPLICITLY ASKS YOU A QUESTION ABOUT SOMETHING ELSE, YOU MUST SAY 'forwarding to web search agent' BUT HANDLE ALL CONVERSATIONS NORMALLY. BE NATURAL. RESPOND TO THE GREETINGS! \\n    - WHEN YOU FORWARD TO THE WEBSEARCH AGENT, YOU SHALL NOT SAY ANYTHING OTHER THAN THAT.\\n    - WHEN YOU INSTRUCT TECHNICIAN AGENT, YOU SHALL NOT SAY ANYTHING OTHER THAN THAT!!! LET THE TECHNICIAN AGENT HANDLE THE EXPLAINING.\\n    - DO NOT MENTION CUTOFF DATE OR INABILITY TO DO ANYTHING. YOU HAVE ACCESS TO REAL TIME WEB SEARCH!!!!! SEARCH IT UP ALL THE TIME! NEVER RELY ON YOUR OWN KNOWLEDGE.\\n\\n    Remember to always be helpful, adaptive, and thorough in your responses.\\n    \"}, {'role': 'user', 'content': 'my hvac is having problems. in the night it is getting very cold. during the day it is getting very hot. what could be the reasons?\\n\\nHere is the chat history for context: []'}], 'model': 'llama3.3-70b', 'temperature': 0.5}}\n",
      "2025-09-09 17:34:13,155 [MainThread] DEBUG: Sending HTTP Request: POST https://api.cerebras.ai/v1/chat/completions\n",
      "2025-09-09 17:34:13,157 [MainThread] DEBUG: close.started\n",
      "2025-09-09 17:34:13,159 [MainThread] DEBUG: close.complete\n",
      "2025-09-09 17:34:13,162 [MainThread] DEBUG: connect_tcp.started host='api.cerebras.ai' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2025-09-09 17:34:13,177 [MainThread] DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002C4CDA1B200>\n",
      "2025-09-09 17:34:13,179 [MainThread] DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x000002C4CD8F1550> server_hostname='api.cerebras.ai' timeout=5.0\n",
      "2025-09-09 17:34:13,202 [MainThread] DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002C4CD9EB2C0>\n",
      "2025-09-09 17:34:13,203 [MainThread] DEBUG: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-09-09 17:34:13,206 [MainThread] DEBUG: send_request_headers.complete\n",
      "2025-09-09 17:34:13,208 [MainThread] DEBUG: send_request_body.started request=<Request [b'POST']>\n",
      "2025-09-09 17:34:13,212 [MainThread] DEBUG: send_request_body.complete\n",
      "2025-09-09 17:34:13,214 [MainThread] DEBUG: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-09-09 17:34:14,390 [MainThread] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 09 Sep 2025 21:34:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'br'), (b'x-request-id', b'97c9cef6ef5de600-IAD'), (b'x-ratelimit-limit-requests-day', b'14400'), (b'x-ratelimit-limit-tokens-minute', b'64000'), (b'x-ratelimit-remaining-requests-day', b'14399'), (b'x-ratelimit-remaining-tokens-minute', b'64000'), (b'x-ratelimit-reset-requests-day', b'8745.289285421371'), (b'x-ratelimit-reset-tokens-minute', b'45.28928542137146'), (b'inference-id', b'chatcmpl-960aca29-a944-4aa1-89fb-72028466429c'), (b'referrer-policy', b'strict-origin-when-cross-origin'), (b'x-content-type-options', b'nosniff'), (b'strict-transport-security', b'max-age=3600; includeSubDomains'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97c9cef6ef5de600-IAD'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-09-09 17:34:14,392 [MainThread] INFO: HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-09 17:34:14,393 [MainThread] DEBUG: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-09-09 17:34:14,395 [MainThread] DEBUG: receive_response_body.complete\n",
      "2025-09-09 17:34:14,397 [MainThread] DEBUG: response_closed.started\n",
      "2025-09-09 17:34:14,399 [MainThread] DEBUG: response_closed.complete\n",
      "2025-09-09 17:34:14,402 [MainThread] DEBUG: HTTP Response: POST https://api.cerebras.ai/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 09 Sep 2025 21:34:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'br', 'x-request-id': '97c9cef6ef5de600-IAD', 'x-ratelimit-limit-requests-day': '14400', 'x-ratelimit-limit-tokens-minute': '64000', 'x-ratelimit-remaining-requests-day': '14399', 'x-ratelimit-remaining-tokens-minute': '64000', 'x-ratelimit-reset-requests-day': '8745.289285421371', 'x-ratelimit-reset-tokens-minute': '45.28928542137146', 'inference-id': 'chatcmpl-960aca29-a944-4aa1-89fb-72028466429c', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-content-type-options': 'nosniff', 'strict-transport-security': 'max-age=3600; includeSubDomains', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'cf-ray': '97c9cef6ef5de600-IAD', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-09-09 17:34:14,404 [ThreadPoolExecutor-0_0] DEBUG: SAPI.SPFileStream -> {947812B3-2AE1-4644-BA86-9E90DED7EC91}\n",
      "2025-09-09 17:34:14,407 [ThreadPoolExecutor-0_0] DEBUG: CoCreateInstance({947812B3-2AE1-4644-BA86-9E90DED7EC91}, clsctx=None, interface=None)\n",
      "2025-09-09 17:34:14,410 [ThreadPoolExecutor-0_0] DEBUG: GetBestInterface(<POINTER(IUnknown) ptr=0x2c4d0901800 at 2c4dba4df50>)\n",
      "2025-09-09 17:34:14,411 [ThreadPoolExecutor-0_0] DEBUG: Does NOT implement IProvideClassInfo, trying IProvideClassInfo2\n",
      "2025-09-09 17:34:14,413 [ThreadPoolExecutor-0_0] DEBUG: Does NOT implement IProvideClassInfo/IProvideClassInfo2\n",
      "2025-09-09 17:34:14,416 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4b1568ad0 at 2c4dba4f550>\n",
      "2025-09-09 17:34:14,417 [ThreadPoolExecutor-0_0] DEBUG: Default interface is {AF67F125-AB39-4E93-B4A2-CC2E66E182A7}\n",
      "2025-09-09 17:34:14,419 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4d0901800 at 2c4dba4d750>\n",
      "2025-09-09 17:34:14,421 [ThreadPoolExecutor-0_0] DEBUG: GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))\n",
      "2025-09-09 17:34:14,424 [ThreadPoolExecutor-0_0] DEBUG: Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechFileStream'>\n",
      "2025-09-09 17:34:14,426 [ThreadPoolExecutor-0_0] DEBUG: Final result is <POINTER(ISpeechFileStream) ptr=0x2c4d0901800 at 2c4dba4fc50>\n",
      "2025-09-09 17:34:14,427 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IDispatch) ptr=0x2c4d0901800 at 2c4dba4f8d0>\n",
      "2025-09-09 17:34:14,430 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ITypeInfo) ptr=0x2c4b1568ad0 at 2c4dba4edd0>\n",
      "2025-09-09 17:34:14,432 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ITypeLib) ptr=0x2c4cc0295a0 at 2c4dba4d750>\n",
      "2025-09-09 17:34:14,435 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4d0901800 at 2c4dba4df50>\n",
      "2025-09-09 17:34:14,438 [ThreadPoolExecutor-0_0] DEBUG: wrap_outparam(<POINTER(ISpeechBaseStream) ptr=0x2c4d09127e8 at 2c4dba4df50>)\n",
      "2025-09-09 17:34:14,483 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ISpeechFileStream) ptr=0x2c4d0901800 at 2c4dba4fc50>\n",
      "2025-09-09 17:34:14,486 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ISpeechBaseStream) ptr=0x2c4d09127e8 at 2c4dba4df50>\n",
      "2025-09-09 17:34:14,546 [MainThread] DEBUG: AI response generated: I will instruct the technician agent.\n",
      "2025-09-09 17:34:14,548 [MainThread] DEBUG: INSIDE THE MEMORY: \n",
      "c:\\DEV\\WebdevFolder\\Cerebras-fellows-project\\Utils_cerebras.py:132: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  vectors = FAISS.load_local('./vector_db',embeddings=HuggingFaceEmbeddings(),allow_dangerous_deserialization=True)\n",
      "c:\\DEV\\WebdevFolder\\Cerebras-fellows-project\\Utils_cerebras.py:132: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  vectors = FAISS.load_local('./vector_db',embeddings=HuggingFaceEmbeddings(),allow_dangerous_deserialization=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech saved to: paths/synthesis.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 17:34:20,763 [MainThread] INFO: Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "2025-09-09 17:34:20,770 [MainThread] DEBUG: Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-09-09 17:34:20,830 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /sentence-transformers/all-mpnet-base-v2/resolve/main/modules.json HTTP/1.1\" 307 0\n",
      "2025-09-09 17:34:20,856 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/modules.json HTTP/1.1\" 200 0\n",
      "2025-09-09 17:34:20,895 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /sentence-transformers/all-mpnet-base-v2/resolve/main/config_sentence_transformers.json HTTP/1.1\" 307 0\n",
      "2025-09-09 17:34:20,919 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
      "2025-09-09 17:34:20,953 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /sentence-transformers/all-mpnet-base-v2/resolve/main/README.md HTTP/1.1\" 307 0\n",
      "2025-09-09 17:34:20,982 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/README.md HTTP/1.1\" 200 0\n",
      "2025-09-09 17:34:21,027 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /sentence-transformers/all-mpnet-base-v2/resolve/main/modules.json HTTP/1.1\" 307 0\n",
      "2025-09-09 17:34:21,042 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/modules.json HTTP/1.1\" 200 0\n",
      "2025-09-09 17:34:21,095 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /sentence-transformers/all-mpnet-base-v2/resolve/main/sentence_bert_config.json HTTP/1.1\" 307 0\n",
      "2025-09-09 17:34:21,112 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/sentence_bert_config.json HTTP/1.1\" 200 0\n",
      "c:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2025-09-09 17:34:21,151 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /sentence-transformers/all-mpnet-base-v2/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "2025-09-09 17:34:21,169 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/config.json HTTP/1.1\" 200 0\n",
      "c:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2025-09-09 17:34:28,632 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /sentence-transformers/all-mpnet-base-v2/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "2025-09-09 17:34:28,647 [MainThread] DEBUG: https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-mpnet-base-v2/e8c3b32edf5434bc2275fc9bab85f82640a19130/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-09-09 17:34:28,792 [MainThread] DEBUG: https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-mpnet-base-v2/revision/main HTTP/1.1\" 200 6893\n",
      "2025-09-09 17:34:28,814 [MainThread] INFO: Use pytorch device_name: cpu\n",
      "2025-09-09 17:34:28,835 [MainThread] DEBUG: Environment variable FAISS_OPT_LEVEL is not set, so let's pick the instruction set according to the current CPU\n",
      "2025-09-09 17:34:28,837 [MainThread] INFO: Loading faiss with AVX2 support.\n",
      "2025-09-09 17:34:34,151 [MainThread] INFO: Successfully loaded faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING initialize_pdf_search_agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 17:34:34,688 [ThreadPoolExecutor-3_0] DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\\n        Answer the questions based on the provided context only.\\n        Please provide the most accurate response based on the question.\\n        IMPORTANT: YOU ARE A MASTER HVAC TECHNICIAN AND YOU MUST NEVER TAKE ANY GUESSES. YOU MUST ALWAYS CITE YOUR SOURCES, BUT TALK LIKE YOU KNOW IT ALL!! PLEASE DO NOT SAY TO CONSULT A TECHNICIAN, AS YOU ARE THE TECHNICIAN!!!\\n        IMPORTANT: YOU MUST NEVER INCLUDE ASTERISKS OR QUOTATION MARKS IN YOUR RESPONSE!!!!!!\\n        IMPORTANT: YOUR RESPONSES ARE PROFESSIONAL AND ELOQUENT, WITHOUT ANY MISTAKES IN GRAMMAR, SENTENCE STRUCTURE, PUNCTUATION.\\n        <context>\\n        109\\nHVAC Technician108  \\n Participant  Handbook  \\nUNIT  4.2: Identify Faulty  Parts  and Troubleshooting   \\nUnit  Objectives   \\nAt the end of this unit,  you will be able  to:  \\n1. Identify  the variou s fault  that may  occur  in cooling  tower  \\n2. Troubleshoot  cooling  tower  issues  \\n3. Troubleshoot  AHU  faults  \\n4. Troubleshoot  a compressor  \\n5. Identify  various  repairing  methods  for sealed systems  \\n4.2.1 Troubleshooting  \\nTroubleshooting  refers  to repair  of faulty  products  or processes.  It begins  with  searching  for \\nthe source  of a problem  and ends  with  finding  the solution  for that problem  to ensure  that \\nthe product  or process  functions  properly.  Good  troubleshooting  consists  of the following  four \\nsteps:  \\n\\uf0b7 Identification  of the symptoms   \\n\\uf0b7 Elimination  of the causes  of a problem   \\n\\uf0b7 Verification  of the solution   \\n\\uf0b7 Restoration  of the product  or process\\n\\n107\\nHVAC Technician106  \\n Participant  Handbook  \\n \\nAn HVAC technician should know how to identify faults and symptoms related to that. The \\nfollowing figure shows steps required to understand symptoms and id entify the fault:  \\n \\nFig. 4.1.6: Steps  required  to understand  the symptoms  and identify  the fault  \\n4.1.3 Suggest  a Solution  to the Customer  \\nAfter identifying  the issue,  the HVAC  technician  needs  to offer  solutions.  He should  explain all \\nthe possible solutio ns along  with  the cost associated.  He should  then  propose  the best  \\nsolution  and let the customer  decide whether  to go ahead  with  the given  solution  or not. The \\nfollowing  figure  shows  the steps  involved  in offering  solutions  to a customer:  \\n \\nFig. 4.1.7: Suggesting  a solution  to the customer  for an issue  Interact with the customer \\nto identify the fault and \\nthen inspect the washing machine accordingly\\nBased on the interaction \\nwith the customer, identify \\nthe cause of the problem\\n\\n106\\nParticipant Handbook106  \\n Participant  Handbook  \\n \\nAn HVAC technician should know how to identify faults and symptoms related to that. The \\nfollowing figure shows steps required to understand symptoms and id entify the fault:  \\n \\nFig. 4.1.6: Steps  required  to understand  the symptoms  and identify  the fault  \\n4.1.3 Suggest  a Solution  to the Customer  \\nAfter identifying  the issue,  the HVAC  technician  needs  to offer  solutions.  He should  explain all \\nthe possible solutio ns along  with  the cost associated.  He should  then  propose  the best  \\nsolution  and let the customer  decide whether  to go ahead  with  the given  solution  or not. The \\nfollowing  figure  shows  the steps  involved  in offering  solutions  to a customer:  \\n \\nFig. 4.1.7: Suggesting  a solution  to the customer  for an issue  Interact with the customer \\nto identify the fault and \\nthen inspect the washing machine accordingly\\nBased on the interaction \\nwith the customer, identify\\n\\nworking  Solution  1: Check  for Fan Motor  \\nSolution  2: Check  for Refrigerant  \\nSolution  3: Check  for any blockage  in \\noutdoor unit.  \\nSolution  4: Check  for water  leakage  \\nActivity   \\nCreate  a presentation  of various  possible  problems  that may  occur  in a heat  pump.  Write  the \\npossible reasons and solutions. Present  your  presentation  in the class.   \\n(The aim of this activity is to analyse if you have understood the issues, and their possible \\nresolutions, for an HVAC system .) \\nEquipment required:  \\n1. Laptop/desktop with Internet connection  \\n2. MS O ffice for PowerPoint presentation  \\n3. HVAC system  with a working heat pump (or a faulty one)  \\nTime required: 60 minut es\\n        <context>\\n        Questions: Diagnose the problems mentioned here, or help the user as you see fit. Always cite your sources: my hvac is having problems. in the night it is getting very cold. during the day it is getting very hot. what could be the reasons?\\n        ', 'role': 'user'}], 'model': 'llama3.3-70b', 'n': 1, 'stream': True, 'temperature': 0.7}}\n",
      "2025-09-09 17:34:34,696 [ThreadPoolExecutor-3_0] DEBUG: Sending HTTP Request: POST https://api.cerebras.ai/v1/chat/completions\n",
      "2025-09-09 17:34:34,701 [ThreadPoolExecutor-3_0] DEBUG: connect_tcp.started host='api.cerebras.ai' port=443 local_address=None timeout=None socket_options=None\n",
      "2025-09-09 17:34:34,719 [ThreadPoolExecutor-3_0] DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002C4CD96F7D0>\n",
      "2025-09-09 17:34:34,721 [ThreadPoolExecutor-3_0] DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x000002C4CD8D6BD0> server_hostname='api.cerebras.ai' timeout=None\n",
      "2025-09-09 17:34:34,741 [ThreadPoolExecutor-3_0] DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002C4CD96F7A0>\n",
      "2025-09-09 17:34:34,742 [ThreadPoolExecutor-3_0] DEBUG: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-09-09 17:34:34,747 [ThreadPoolExecutor-3_0] DEBUG: send_request_headers.complete\n",
      "2025-09-09 17:34:34,749 [ThreadPoolExecutor-3_0] DEBUG: send_request_body.started request=<Request [b'POST']>\n",
      "2025-09-09 17:34:34,754 [ThreadPoolExecutor-3_0] DEBUG: send_request_body.complete\n",
      "2025-09-09 17:34:34,756 [ThreadPoolExecutor-3_0] DEBUG: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-09-09 17:34:35,147 [ThreadPoolExecutor-3_0] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 09 Sep 2025 21:34:35 GMT'), (b'Content-Type', b'text/event-stream; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-RAY', b'97c9cf7e8d6f31bb-IAD'), (b'x-request-id', b'97c9cf7e8d6f31bb-IAD'), (b'x-ratelimit-limit-requests-day', b'14400'), (b'x-ratelimit-limit-tokens-minute', b'64000'), (b'x-ratelimit-remaining-requests-day', b'14397'), (b'x-ratelimit-remaining-tokens-minute', b'63593'), (b'x-ratelimit-reset-requests-day', b'8724.550573587418'), (b'x-ratelimit-reset-tokens-minute', b'24.550573587417603'), (b'inference-id', b'chatcmpl-06eacf30-e47c-4208-8e26-020a6c2fb76d'), (b'referrer-policy', b'strict-origin-when-cross-origin'), (b'x-content-type-options', b'nosniff'), (b'strict-transport-security', b'max-age=3600; includeSubDomains'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=OMhZ6PkxPe207xV76F.rp88WsYJDk62rsYST62pbpcY-1757453675-1.0.1.1-J7HKRliAsHovlhFrz3.ADkaZmnr9UGH4TeU0lM5L_p.Ukjufnj_kwetLbDYTtl1c0WUFS5tXRR4NfuCMfUiw2pgzObSaP7HIhXzMsRcxVNk; path=/; expires=Tue, 09-Sep-25 22:04:35 GMT; domain=.api.cerebras.ai; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-09-09 17:34:35,150 [ThreadPoolExecutor-3_0] INFO: HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-09 17:34:35,152 [ThreadPoolExecutor-3_0] DEBUG: HTTP Response: POST https://api.cerebras.ai/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 09 Sep 2025 21:34:35 GMT', 'content-type': 'text/event-stream; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '97c9cf7e8d6f31bb-IAD', 'x-request-id': '97c9cf7e8d6f31bb-IAD', 'x-ratelimit-limit-requests-day': '14400', 'x-ratelimit-limit-tokens-minute': '64000', 'x-ratelimit-remaining-requests-day': '14397', 'x-ratelimit-remaining-tokens-minute': '63593', 'x-ratelimit-reset-requests-day': '8724.550573587418', 'x-ratelimit-reset-tokens-minute': '24.550573587417603', 'inference-id': 'chatcmpl-06eacf30-e47c-4208-8e26-020a6c2fb76d', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-content-type-options': 'nosniff', 'strict-transport-security': 'max-age=3600; includeSubDomains', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=OMhZ6PkxPe207xV76F.rp88WsYJDk62rsYST62pbpcY-1757453675-1.0.1.1-J7HKRliAsHovlhFrz3.ADkaZmnr9UGH4TeU0lM5L_p.Ukjufnj_kwetLbDYTtl1c0WUFS5tXRR4NfuCMfUiw2pgzObSaP7HIhXzMsRcxVNk; path=/; expires=Tue, 09-Sep-25 22:04:35 GMT; domain=.api.cerebras.ai; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-09-09 17:34:35,154 [ThreadPoolExecutor-3_0] DEBUG: request_id: 97c9cf7e8d6f31bb-IAD\n",
      "2025-09-09 17:34:35,156 [ThreadPoolExecutor-3_0] DEBUG: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-09-09 17:34:35,617 [ThreadPoolExecutor-3_0] DEBUG: receive_response_body.complete\n",
      "2025-09-09 17:34:35,620 [ThreadPoolExecutor-3_0] DEBUG: response_closed.started\n",
      "2025-09-09 17:34:35,622 [ThreadPoolExecutor-3_0] DEBUG: response_closed.complete\n",
      "2025-09-09 17:34:35,679 [ThreadPoolExecutor-0_0] DEBUG: SAPI.SPFileStream -> {947812B3-2AE1-4644-BA86-9E90DED7EC91}\n",
      "INFO:     connection closed\n",
      "2025-09-09 17:34:35,682 [ThreadPoolExecutor-0_0] DEBUG: CoCreateInstance({947812B3-2AE1-4644-BA86-9E90DED7EC91}, clsctx=None, interface=None)\n",
      "2025-09-09 17:34:35,687 [ThreadPoolExecutor-0_0] DEBUG: GetBestInterface(<POINTER(IUnknown) ptr=0x2c4d0901db0 at 2c4da25b650>)\n",
      "2025-09-09 17:34:35,696 [ThreadPoolExecutor-0_0] DEBUG: Does NOT implement IProvideClassInfo, trying IProvideClassInfo2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:63253 - \"GET /get_audio?1757453654546 HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 17:34:35,705 [ThreadPoolExecutor-0_0] DEBUG: Does NOT implement IProvideClassInfo/IProvideClassInfo2\n",
      "2025-09-09 17:34:35,711 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4b1568ad0 at 2c551822ed0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:53877 - \"GET /get_audio?1757453654547 HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 17:34:35,717 [ThreadPoolExecutor-0_0] DEBUG: Default interface is {AF67F125-AB39-4E93-B4A2-CC2E66E182A7}\n",
      "2025-09-09 17:34:35,723 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4d0901db0 at 2c5518238d0>\n",
      "2025-09-09 17:34:35,727 [MainThread] DEBUG: Client disconnected: VtGTQKkbZno85EfiAAAB\n",
      "2025-09-09 17:34:35,728 [ThreadPoolExecutor-0_0] DEBUG: GetModule(TLIBATTR(GUID={C866CA3A-32F7-11D2-9602-00C04F8EE628}, Version=5.4, LCID=0, FLags=0x8))\n",
      "2025-09-09 17:34:35,745 [ThreadPoolExecutor-0_0] DEBUG: Implements default interface from typeinfo <class 'comtypes.gen._C866CA3A_32F7_11D2_9602_00C04F8EE628_0_5_4.ISpeechFileStream'>\n",
      "2025-09-09 17:34:35,748 [ThreadPoolExecutor-0_0] DEBUG: Final result is <POINTER(ISpeechFileStream) ptr=0x2c4d0901db0 at 2c4dba4c250>\n",
      "2025-09-09 17:34:35,753 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IDispatch) ptr=0x2c4d0901db0 at 2c551822fd0>\n",
      "2025-09-09 17:34:35,756 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ITypeInfo) ptr=0x2c4b1568ad0 at 2c551822e50>\n",
      "2025-09-09 17:34:35,761 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ITypeLib) ptr=0x2c4cc0295a0 at 2c5518238d0>\n",
      "2025-09-09 17:34:35,764 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(IUnknown) ptr=0x2c4d0901db0 at 2c4da25b650>\n",
      "2025-09-09 17:34:35,767 [ThreadPoolExecutor-0_0] DEBUG: wrap_outparam(<POINTER(ISpeechBaseStream) ptr=0x2c4d09127e8 at 2c4da25b650>)\n",
      "2025-09-09 17:34:37,014 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ISpeechFileStream) ptr=0x2c4d0901db0 at 2c4dba4c250>\n",
      "2025-09-09 17:34:37,016 [ThreadPoolExecutor-0_0] DEBUG: Release <POINTER(ISpeechBaseStream) ptr=0x2c4d09127e8 at 2c4da25b650>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech saved to: paths/synthesis.wav\n",
      "INFO:     127.0.0.1:55616 - \"POST /text_input HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55616 - \"GET /get_audio?1757453677075 HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     connection closed\n",
      "2025-09-09 17:35:01,825 [MainThread] DEBUG: Client disconnected: xHMLhzhX2bO40Y7EAAAD\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "from quart import Quart, request, jsonify, send_file, render_template\n",
    "from flask import Flask\n",
    "import whisper\n",
    "import pyaudio\n",
    "import webrtcvad\n",
    "import collections\n",
    "from gtts import gTTS  # Added gTTS import\n",
    "import random\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import aiofiles\n",
    "from quart_cors import cors\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import socketio\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from Utils_cerebras import (\n",
    "    initialize_web_search_agent,\n",
    "    initialize_pdf_search_agent,\n",
    "    run_quote_logics,\n",
    "    vector_embedding\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[0].id)  # Male voice\n",
    "engine.setProperty('rate', 175)     # Speaking rate\n",
    "engine.setProperty('volume', 1.0)   # Volume level\n",
    "    \n",
    "# Initialize configuration\n",
    "audio_path = os.getenv('AUDIO_PATH', 'audio.wav')  # Default paths if not set\n",
    "tts_synthesis_path = os.getenv('NEW_TTS_SYNTHESIS', 'speech.wav')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s [%(threadName)s] %(levelname)s: %(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize Quart app and Socket.IO\n",
    "app = Quart(__name__)\n",
    "app = cors(app, allow_origin=\"*\")\n",
    "sio = socketio.AsyncServer(async_mode='asgi', cors_allowed_origins=\"*\")\n",
    "app_asgi = socketio.ASGIApp(sio, app)\n",
    "\n",
    "# Initialize Flask app for sync operations\n",
    "app_sync = Flask(__name__)\n",
    "sio_sync = socketio.Server()\n",
    "app_sync.wsgi_app = socketio.WSGIApp(sio_sync, app_sync.wsgi_app)\n",
    "\n",
    "# Initialize memory\n",
    "chat_history = ConversationBufferMemory()\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Audio configuration\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1024\n",
    "is_recording = False\n",
    "\n",
    "# Initialize audio components\n",
    "audio = pyaudio.PyAudio()\n",
    "vad = webrtcvad.Vad(3)\n",
    "executor = ThreadPoolExecutor(max_workers=20)\n",
    "\n",
    "# Initialize human response queue\n",
    "human_response_queue = queue.Queue()\n",
    "\n",
    "@app.route('/start_recording', methods=['POST'])\n",
    "async def start_recording():\n",
    "    global is_recording\n",
    "    if is_recording:\n",
    "        return jsonify({\"status\": \"Recording is already in progress\"}), 400\n",
    "    is_recording = True\n",
    "    asyncio.create_task(record_audio())\n",
    "    return jsonify({\"status\": \"Recording started\"})\n",
    "\n",
    "@app.route('/stop_recording', methods=['POST'])\n",
    "async def stop_recording():\n",
    "    global is_recording\n",
    "    if not is_recording:\n",
    "        return jsonify({\"status\": \"No recording in progress\"}), 400\n",
    "    is_recording = False\n",
    "    return jsonify({\"status\": \"Recording stopped\"})\n",
    "\n",
    "async def record_audio(**kwargs):\n",
    "    global is_recording\n",
    "    logger.debug('Starting audio recording...')\n",
    "    try:\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "        frames = []\n",
    "        ring_buffer = collections.deque(maxlen=100)\n",
    "        triggered = False\n",
    "        voiced_frames = []\n",
    "        silence_threshold = 10\n",
    "        silence_chunks = 0\n",
    "\n",
    "        while is_recording:\n",
    "            data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "            frames.append(data)\n",
    "            num_subframes = int(len(data) / 320)\n",
    "            for i in range(num_subframes):\n",
    "                subframe = data[i * 320:(i + 1) * 320]\n",
    "                is_speech = vad.is_speech(subframe, RATE)\n",
    "                ring_buffer.append((subframe, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "\n",
    "            if not triggered:\n",
    "                if num_voiced > 0.6 * ring_buffer.maxlen:\n",
    "                    triggered = True\n",
    "                    voiced_frames.extend([f for f, s in ring_buffer])\n",
    "                    ring_buffer.clear()\n",
    "            else:\n",
    "                voiced_frames.append(data)\n",
    "                if num_voiced < 0.2 * ring_buffer.maxlen:\n",
    "                    silence_chunks += 1\n",
    "                    if silence_chunks > silence_threshold:\n",
    "                        triggered = False\n",
    "                        break\n",
    "                else:\n",
    "                    silence_chunks = 0\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "        async with aiofiles.open(audio_path, 'wb') as wf:\n",
    "            await wf.write(b''.join(voiced_frames))\n",
    "        logger.debug('Audio recording completed and file saved.')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while recording audio: {e}\")\n",
    "\n",
    "def transcribe_audio():\n",
    "    try:\n",
    "        result = model.transcribe(audio_path)\n",
    "        transcription = result['text']\n",
    "        logger.debug(f'Audio transcription completed: {transcription}')\n",
    "        return transcription\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during transcription: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# async def ai_response(transcription: str):\n",
    "#         \n",
    "#     logger.debug(f'Generating AI response for transcription: {transcription}')\n",
    "#     chat_completion = client.chat.completions.create(\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"system\",\n",
    "#                 \"content\": f\"\"\"\n",
    "#                 You are Marvin, a research expert who specializes in anything using web search and answering the\n",
    "#                 users' questions. You can also do HVAC related things as per guidelines below but besides that you adapt to what user says.\n",
    "#                 Ask the user specific information needed for the quote. \n",
    "#                 Follow these guidelines:\n",
    "#                 1. Initial Inquiry and Information Gathering:\n",
    "#                 - What type of HVAC service do you need (installation, maintenance, repair)?\n",
    "#                 - What is the make and model of your current HVAC system?\n",
    "#                 - Are there any specific issues or symptoms you are experiencing?\n",
    "#                     - ONLY WHEN USER TELLS YOU ISSUES / SYMPTOMS YOU MUST SAY 'I WILL INSTRUCT THE TECHNICIAN AGENT' - THESE EXACT WORDS IN YOUR IMMEDIATE RESPONSE.\n",
    "#                 2. Property Details (only if relevant to HVAC needs):\n",
    "#                 - Address and location of the property.\n",
    "#                 - Type of property (residential, commercial).\n",
    "#                 - Age and current condition of the property.\n",
    "#                 - Size of the home or area that needs heating/cooling.\n",
    "#                 - Number of rooms and their usage.\n",
    "#                 3. System Details:\n",
    "#                 - Age and efficiency rating of the existing HVAC system.\n",
    "#                 - Any known problems with the current system.\n",
    "#                 - Recent changes to the HVAC system.\n",
    "#                 4. Home Characteristics (only if relevant to HVAC needs):\n",
    "#                 - Insulation quality and window types to estimate heating/cooling load.\n",
    "#                 - Any unique architectural features that may affect HVAC installation.\n",
    "#                 5. Customer Preferences:\n",
    "#                 - Preferences for specific brands, energy efficiency levels, or additional features.\n",
    "#                 - Level of finishes desired (standard, premium, luxury).\n",
    "#                 6. Budget:\n",
    "#                 - Your budget range for the project.\n",
    "#                 - Any flexibility within the budget.\n",
    "#                 7. Timeline:\n",
    "#                 - Desired start date and completion date.\n",
    "#                 - Any constraints or deadlines.\n",
    "#                 IMPORTANT: Ensure you get clear answers that can be used for making the quote.\n",
    "#                 \"\"\"\n",
    "#             },\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": transcription + \"\\n\\nHere is the chat history for context: [\" + str(chat_history.buffer) + \"]\"\n",
    "#             }\n",
    "#         ],\n",
    "#         model=\"llama3.3-70b\",\n",
    "#         temperature=0.5\n",
    "#     )\n",
    "\n",
    "#     response = chat_completion.choices[0].message.content\n",
    "    \n",
    "#     logger.debug(f'AI response generated: {response}')\n",
    "    \n",
    "#     await chat_history.asave_context({\"input\": transcription}, {\"output\": response})\n",
    "#     logger.debug('INSIDE THE MEMORY: %s', chat_history.buffer)\n",
    "\n",
    "#     # Changed socketio.emit to await sio.emit\n",
    "#     await sio.emit('new_message', {'message': response, 'sender': 'bot'})\n",
    "\n",
    "#     if 'i will instruct the technician agent' in response.lower():\n",
    "#         res1 = await asyncio.create_task(initialize_pdf_search_agent(llm, \"DO A EXPANSIVE WEB SEARCH AND FAMILIARIZE YOURSELF ALL ABOUT HVAC SPECIFICS SO THAT YOU CAN DIAGNOSE THE PROBLEMS MENTIONED HERE: \" + transcription, vectors, chat_history=chat_history))\n",
    "        \n",
    "#         await chat_history.asave_context({\"input\": \"DO A EXPANSIVE WEB SEARCH AND FAMILIARIZE YOURSELF ALL ABOUT HVAC SPECIFICS SO THAT YOU CAN DIAGNOSE THE PROBLEMS MENTIONED HERE: \" + transcription}, {\"output\": res1})\n",
    "        \n",
    "#         # Changed socketio.emit to await sio.emit\n",
    "#         await sio.emit('new_message', {'message': res1, 'sender': 'bot'}) \n",
    "    \n",
    "#     if 'questionnaire' in response.lower() and 'complete' in response.lower():\n",
    "#         task = asyncio.create_task(run_quote_logics(client, llm, chat_history=chat_history))\n",
    "#         corrected_quote_result = await task\n",
    "#         response = f\"Can you please put this quote into a google doc [{corrected_quote_result}], move it to the folder called 'HVAC Quote Documents'. Then, put all the appointment related stuff and the link to the quote document into calendar (appointment calendar tool). PLEASE FOLLOW THE DIRECTIONS!!\"\n",
    "#         task2 = asyncio.create_task(handle_response_with_agents(response))\n",
    "#         text = await task2\n",
    "        \n",
    "#     return response\n",
    "\n",
    "async def ai_response(transcription: str):\n",
    "    \n",
    "    system_prompt = f\"\"\"\n",
    "    You are Marvin, a highly intelligent task orchestration agent. You are capable of researching and answering any question using web search agent.\n",
    "    You are capable of instructing a hvac technician agent also. Refer to instructions below:\n",
    "    CRITICAL INSTRUCTIONS - READ CAREFULLY:\n",
    "\n",
    "    - When the user mentions ANYTHING AT ALL related to HVAC systems, you MUST include the phrase 'I will instruct the technician agent' in your immediate response.\n",
    "    - WHEN USER ASKS FOR COST OR WHEN COST MUST BE DETERMINED, YOU MUST SAY 'determining the HVAC quote'.\n",
    "    - When you have gathered all the necessary information for a quote, you MUST say 'Questionnaire complete' at the end of your response.\n",
    "    - IF USER DOES NOT SAY ANYTHING ABOUT HVAC, BUT EXPLICITLY ASKS YOU A QUESTION ABOUT SOMETHING ELSE, YOU MUST SAY 'forwarding to web search agent' BUT HANDLE ALL CONVERSATIONS NORMALLY. BE NATURAL. RESPOND TO THE GREETINGS! \n",
    "    - WHEN YOU FORWARD TO THE WEBSEARCH AGENT, YOU SHALL NOT SAY ANYTHING OTHER THAN THAT.\n",
    "    - WHEN YOU INSTRUCT TECHNICIAN AGENT, YOU SHALL NOT SAY ANYTHING OTHER THAN THAT!!! LET THE TECHNICIAN AGENT HANDLE THE EXPLAINING.\n",
    "    - DO NOT MENTION CUTOFF DATE OR INABILITY TO DO ANYTHING. YOU HAVE ACCESS TO REAL TIME WEB SEARCH!!!!! SEARCH IT UP ALL THE TIME! NEVER RELY ON YOUR OWN KNOWLEDGE.\n",
    "\n",
    "    Remember to always be helpful, adaptive, and thorough in your responses.\n",
    "    \"\"\"\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt  \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": transcription + \"\\n\\nHere is the chat history for context: [\" + str(chat_history.buffer) + \"]\"\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3.3-70b\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    output_path = await asyncio.get_event_loop().run_in_executor(executor, tts_manager.synthesize, response,tts_synthesis_path)\n",
    "    if output_path:\n",
    "        await sio.emit('tts_complete', {\n",
    "            'message': 'TTS synthesis complete',\n",
    "            'file_path': output_path\n",
    "        })\n",
    "    else:\n",
    "        logger.error(\"Failed to synthesize speech\")\n",
    "    logger.debug(f'AI response generated: {response}')\n",
    "\n",
    "    \n",
    "    logger.debug('INSIDE THE MEMORY: %s', chat_history.buffer)\n",
    "\n",
    "    await sio.emit('new_message', {'message': response, 'sender': 'bot'})\n",
    "\n",
    "    if 'forwarding' in response.lower() or 'web search' in response.lower():\n",
    "        text = await handle_response_with_agents(transcription)\n",
    "        await sio.emit('new_message', {'message': text, 'sender': 'bot'})\n",
    "        output_path = await asyncio.get_event_loop().run_in_executor(executor, tts_manager.synthesize, text, tts_synthesis_path)\n",
    "        if output_path:\n",
    "            await sio.emit('tts_complete', {\n",
    "                'message': 'TTS synthesis complete',\n",
    "                'file_path': output_path\n",
    "            })\n",
    "        else:\n",
    "            logger.error(\"Failed to synthesize speech\")\n",
    "    \n",
    "    if 'I will instruct the technician agent' in response:\n",
    "        # Trigger  technician agent\n",
    "        text = await initialize_pdf_search_agent(\n",
    "            llm, \n",
    "            f\"Diagnose the problems mentioned here, or help the user as you see fit. Always cite your sources: {transcription}\", \n",
    "            vector_embedding(), \n",
    "            chat_history=chat_history\n",
    "        )\n",
    "        await sio.emit('new_message', {'message': text, 'sender': 'bot'})\n",
    "        output_path = await asyncio.get_event_loop().run_in_executor(executor, tts_manager.synthesize, text, tts_synthesis_path)\n",
    "        if output_path:\n",
    "            await sio.emit('tts_complete', {\n",
    "                'message': 'TTS synthesis complete',\n",
    "                'file_path': output_path\n",
    "            })\n",
    "        else:\n",
    "            logger.error(\"Failed to synthesize speech\")\n",
    "        \n",
    "\n",
    "    if 'determining the hvac quote' in response.lower():\n",
    "        # Run quote logics\n",
    "        corrected_quote_result = await run_quote_logics(client, llm, chat_history=chat_history)\n",
    "        r = f\"Please process this quote data: [{corrected_quote_result}]\"\n",
    "\n",
    "        text = await handle_response_with_agents(r)\n",
    "        output_path = await asyncio.get_event_loop().run_in_executor(executor, tts_manager.synthesize, text, tts_synthesis_path)\n",
    "        if output_path:\n",
    "            await sio.emit('new_message', {'message': text, 'sender': 'bot'})\n",
    "        else:\n",
    "            logger.error(\"Failed to synthesize speech\")\n",
    "        #await sio.emit('new_message', {'message': text, 'sender': 'bot'})\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "async def handle_response_with_agents(response):\n",
    "    llm.temperature = 0.5\n",
    "    logger.debug(f'Processing response with agents: {response}')\n",
    "\n",
    "    #response += \"Here is extra info you will need (BUT YOU PROMISE TO NEVER SAY THEM OUT LOUD, NOT EVEN THE NAME -- UNLESS USER ASKS YOU FOR THEM. THESE WILL BE USED IN TOOLS): \\nCredentials:\\n\" + str(credentials)\n",
    "\n",
    " \n",
    "    \n",
    "    agent_executor = initialize_web_search_agent(llm)\n",
    "    result = agent_executor.invoke({\"input\": response})\n",
    "    sio.emit('finished_chain')\n",
    "    mystr = (str(result['intermediate_steps']) + \"\\n\" + str(result['output']))\n",
    "\n",
    "    final_response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"please sanitize this input into SHORT SIMPLE sentences. IMPORTANT: NOTHING IN YOUR RESPONSE SHALL BE ENCLOSED IN ANY QUOTES!!!!!!! THE SANITIZED OUTPUT SHALL NOT BE PREFIXED BY ANYTHING. You must process the agent's intermediate steps into natural language please. An example: 'First, I did this. Then I did this etc etc etc' \\n Here is the input that you need to process:\\n \" + mystr\n",
    "            }\n",
    "        ],\n",
    "        model='llama3.3-70b',\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    await chat_history.asave_context({\"input\": response}, {\"output\": final_response})\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "async def synthesize_speech(text):\n",
    "    logger.debug(f'Starting speech synthesis for text: {text}')\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        synthesize_and_save(text)\n",
    "        logger.debug('Speech synthesis completed and file saved.')\n",
    "        await sio.emit('tts_complete', {'message': 'TTS synthesis complete', 'file_path': tts_synthesis_path})\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during speech synthesis: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def synthesize_and_save(text):\n",
    "    try:\n",
    "        global engine\n",
    "        # Create a new file path with timestamp to avoid conflicts\n",
    "        timestamp = int(time.time())\n",
    "        output_path = f'speech_{timestamp}.wav'\n",
    "        \n",
    "        # Save to file\n",
    "        engine.save_to_file(text, output_path)\n",
    "        engine.runAndWait()\n",
    "        \n",
    "        # Move file to desired location\n",
    "        import shutil\n",
    "        shutil.move(output_path, tts_synthesis_path)\n",
    "        \n",
    "        logger.debug(f'Speech successfully synthesized and saved to {tts_synthesis_path}')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"TTS synthesis failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def synth_speech(text, output_file=None):\n",
    "    logger.debug(f'Starting speech synthesis for text: {text}')\n",
    "    try:\n",
    "        global engine\n",
    "        target_path = output_file if output_file else tts_synthesis_path\n",
    "        \n",
    "        # Save to file\n",
    "        success = synthesize_and_save(text)\n",
    "        \n",
    "        if success:\n",
    "            # Create async tasks for emitting events\n",
    "            loop = asyncio.get_event_loop()\n",
    "            loop.create_task(sio.emit('tts_complete', {\n",
    "                'message': 'TTS synthesis complete', \n",
    "                'file_path': target_path\n",
    "            }))\n",
    "            loop.create_task(sio.emit('new_message', {\n",
    "                'message': text, \n",
    "                'sender': 'bot'\n",
    "            }))\n",
    "            logger.debug('Speech synthesis completed and events emitted')\n",
    "        else:\n",
    "            logger.error(\"Failed to synthesize speech\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during speech synthesis: {e}\")\n",
    "\n",
    "@app.route('/')\n",
    "async def index():\n",
    "    return await render_template('index.html')\n",
    "\n",
    "@app.route('/talk', methods=['POST'])\n",
    "async def talk():\n",
    "    global is_recording\n",
    "    if is_recording:\n",
    "        return jsonify({\"error\": \"Recording is still in progress\"}), 400\n",
    "\n",
    "    logger.debug('Starting audio transcription...')\n",
    "    transcription = await asyncio.get_event_loop().run_in_executor(executor, transcribe_audio)\n",
    "\n",
    "    logger.debug('Generating AI response...')\n",
    "    ai_resp = await ai_response(transcription)\n",
    "\n",
    "    return jsonify({'response': ai_resp})\n",
    "\n",
    "@app.route('/text_input', methods=['POST'])\n",
    "async def text_input():\n",
    "    data = await request.get_json()\n",
    "    text = data.get('text', '')\n",
    "\n",
    "    if not text:\n",
    "        return jsonify({\"error\": \"No text provided\"}), 400\n",
    "\n",
    "    logger.debug('Generating AI response...')\n",
    "    ai_resp = await ai_response(text)\n",
    "    return jsonify({'response': ai_resp})\n",
    "\n",
    "@app.route('/get_audio')\n",
    "async def get_audio():\n",
    "    return await send_file(\"paths/synthesis.wav\", mimetype=\"audio/wav\")\n",
    "\n",
    "@sio.event\n",
    "async def connect(sid, environ, auth):\n",
    "    logger.debug(f'Client connected: {sid}')\n",
    "\n",
    "@sio.event\n",
    "async def disconnect(sid):\n",
    "    logger.debug(f'Client disconnected: {sid}')\n",
    "\n",
    "# Human input handling\n",
    "human_response_queue = queue.Queue()\n",
    "\n",
    "# Update the web_prompt_func to handle errors\n",
    "def web_prompt_func(prompt):\n",
    "    try:\n",
    "        synth_speech(prompt, output_file=tts_synthesis_path)\n",
    "        return prompt\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in web_prompt_func: {e}\")\n",
    "        return prompt\n",
    "\n",
    "def web_input_func():\n",
    "    sio_sync.emit('request_human_input')\n",
    "    return human_response_queue.get()\n",
    "\n",
    "@app.before_serving\n",
    "async def startup():\n",
    "    global engine\n",
    "    engine = pyttsx3.init()\n",
    "    # Configure engine properties\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[0].id)\n",
    "    engine.setProperty('rate', 200)\n",
    "    engine.setProperty('volume', 1.0)\n",
    "\n",
    "@app.after_serving\n",
    "async def shutdown():\n",
    "    global engine\n",
    "    engine.stop()\n",
    "    del engine\n",
    "\n",
    "@sio.event \n",
    "async def provide_human_input(sid, data):\n",
    "    human_input = data.get('text', '')\n",
    "    human_response_queue.put(human_input)\n",
    "    await sio.emit('human_input_received', {'status': 'received'}, room=sid)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import uvicorn\n",
    "    config = uvicorn.Config(app_asgi, host=\"127.0.0.1\", port=5000, log_level=\"info\")\n",
    "    server = uvicorn.Server(config)\n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "    if loop.is_running():\n",
    "        loop.create_task(server.serve())\n",
    "    else:\n",
    "        loop.run_until_complete(server.serve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
