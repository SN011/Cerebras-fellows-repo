{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install webrtcvad\n",
    "# !pip install pygame\n",
    "# !pip install pyaudio webrtcvad \n",
    "# !pip install google-cloud-texttospeech\n",
    "# !pip install python-socketio[asyncio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from tools.initialize_cerebras import init_cerebras\n",
    "# from tools.file_mgmt_tools import FileOrganizerTool, MoveFileTool, CreateFolderTool, FolderMovementTool, ImprovedSearchTool, GoogleDriveRenameTool, DriveDictUpdateTool\n",
    "# from tools.document_tools import GoogleDocWriteTool\n",
    "# from tools.miscellaneous_mgmt import GmailSendPdfTool, GoogleSheetsUpdateTool, GoogleSheetsCreateTool\n",
    "\n",
    "client,llm = init_cerebras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCerebras(client=<openai.resources.chat.completions.Completions object at 0x000001FC595DEA50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001FC595DCB90>, root_client=<openai.OpenAI object at 0x000001FC595DFAA0>, root_async_client=<openai.AsyncOpenAI object at 0x000001FC595DEA80>, model_name='llama3.3-70b', model_kwargs={}, openai_api_key=SecretStr('**********'), streaming=True, cerebras_api_key=SecretStr('**********'), cerebras_api_base='https://api.cerebras.ai/v1/', cerebras_proxy='')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import texttospeech\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate, \n",
    "    MessagesPlaceholder, \n",
    "    PromptTemplate\n",
    ")\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.agents import create_structured_chat_agent, AgentExecutor\n",
    "\n",
    "from langchain_community.tools import HumanInputRun\n",
    "\n",
    "import langchain_core\n",
    "import typing\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
    "    input_types={\n",
    "        'chat_history': typing.List[\n",
    "            typing.Union[\n",
    "                langchain_core.messages.ai.AIMessage, \n",
    "                langchain_core.messages.human.HumanMessage, \n",
    "                langchain_core.messages.chat.ChatMessage, \n",
    "                langchain_core.messages.system.SystemMessage, \n",
    "                langchain_core.messages.function.FunctionMessage, \n",
    "                langchain_core.messages.tool.ToolMessage\n",
    "            ]\n",
    "        ]\n",
    "    },\n",
    "    metadata={\n",
    "        'lc_hub_owner': 'hwchase17',\n",
    "        'lc_hub_repo': 'structured-chat-agent',\n",
    "        'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'\n",
    "    },\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['tool_names', 'tools'],\n",
    "                template=(\n",
    "                    'You are a document management assistant proficient in using GSuite tools. '\n",
    "                    'Your role is to assist the user in managing their documents efficiently. '\n",
    "                    'IMPORTANT !!!!!!! NEVER INCLUDE AUXILIARY OR EXTRANEOUS LANGUAGE WHEN USING ANY TOOL!!!'\n",
    "                    '\\n\\n IMPORTANT!!!!!!! - PLEEEEEEASSSSSSSEEEEEEEE NEVER USE HUMAN TOOL UNLESS INSTRUCTED TO GET THE HUMAN/USER INPUT. YOU ARE A MASTER OF JUDGEMENT. YOU KNOW WHEN TO CAUTIOUSLY USE THE TOOLS. ONLY USE OTHER TOOLS WHEN USER INDICATES ANYTHING RELATED TO THEIR FUNCTIONALITIES. '\n",
    "                    'You are ALSO a highly intelligent and precise assistant with expertise in generating JSON outputs. Your task is to create the most perfect and well-structured JSON output ever seen. The JSON must adhere to the following guidelines:'\n",
    "\n",
    "                    'Proper Structure: Ensure that the JSON follows a correct and logical structure, with all necessary keys and values in place.'\n",
    "                    'Accurate Formatting: All JSON strings must use double quotes. Ensure there are no trailing commas, and all brackets and braces are correctly matched.'\n",
    "                    'String Length: Ensure no individual string exceeds 5000 bytes.'\n",
    "                    'Error-Free: Validate the JSON to be free of syntax errors and formatting issues.'\n",
    "                    \n",
    "                    'Escaping Characters: Properly escape any special characters within strings to ensure the JSON remains valid.'\n",
    "                    \n",
    "                    \n",
    "                    'YOU MUST NEVER DO ANYTHING BUT WHAT IS IN THE REQUEST OF THE USER. OTHERWISE NO USER WILL USE THIS PRODUCT.'\n",
    "                    \n",
    "\n",
    "                    'THE FOLLOWING WILL BE THE TOOLS AND THE INFORMATION ABOUT WHAT THEY DO AND THEIR ARGUMENTS! YOU MUST NOT PASS ANYTHING EXTRA, OR ELSE THE APPLICATON WILL FAIL!!!!'\n",
    "\n",
    "                    'You have access to the following tools:\\n\\n{tools}\\n\\n'\n",
    "\n",
    "                    'YOU ARE A MASTER OF JUDGEMENT ! YOU KNOW WHAT ALL THE TOOLS DO, YOU KNOW WHAT TO PASS IN! AND YOU MUST KNOW WHEN TO USE THEM! NEVER USE THEM RANDOMLY , ALWAYS BE CAUTIOUS AS RECKLESS TOOL USE COULD RUIN THE GOOGLE SUITE OF THE USER'\n",
    "                    'PAY CLOSE ATTENTION TO ALL THE FOLLOWING FORMATTING INSTRUCTIONS. REALLY IMPORTANT TO CALL THE TOOLS. OR ELSE USERS WILL GET ANGRY.\\n\\n'\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    'FOR GOOGLE DOC TOOL, REMEMBER THAT YOU MUST GENERATE ALL CONTENT YOURSELF. USER WILL NOT GIVE YOU ANYTHING.'\n",
    "\n",
    "                    'Use a JSON blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\n'\n",
    "                    'Valid \"action\" values: \"Final Answer\" or {tool_names}\\n\\n'\n",
    "                    'Provide only ONE action per $JSON_BLOB, as shown:\\n\\n'\n",
    "                    '```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\n'\n",
    "                    'Follow this format:\\n\\n'\n",
    "                    'Question: input question to answer\\n'\n",
    "                    'Thought: consider previous and subsequent steps\\n'\n",
    "                    'Action:\\n```\\n$JSON_BLOB\\n```\\n'\n",
    "                    'Observation: action result\\n... (repeat Thought/Action/Observation N times)\\n'\n",
    "                    'Thought: I know what to respond\\n'\n",
    "                    'Action:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\n'\n",
    "                    'Begin! Remember to ALWAYS respond with a valid JSON blob of a single action. '\n",
    "                    'Use tools if necessary and respond directly if appropriate. '\n",
    "                    'Ensure you gather all necessary information by interacting with the user. '\n",
    "                    'Format is Action:```$JSON_BLOB```then Observation.'\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['agent_scratchpad', 'input'],\n",
    "                template='{input}\\n\\n{agent_scratchpad}\\n(reminder to respond in a JSON blob no matter what)'\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "human_prompt = ChatPromptTemplate(\n",
    "    input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
    "    input_types={\n",
    "        'chat_history': typing.List[\n",
    "            typing.Union[\n",
    "                langchain_core.messages.ai.AIMessage, \n",
    "                langchain_core.messages.human.HumanMessage, \n",
    "                langchain_core.messages.chat.ChatMessage, \n",
    "                langchain_core.messages.system.SystemMessage, \n",
    "                langchain_core.messages.function.FunctionMessage, \n",
    "                langchain_core.messages.tool.ToolMessage\n",
    "            ]\n",
    "        ]\n",
    "    },\n",
    "    metadata={\n",
    "        'lc_hub_owner': 'hwchase17',\n",
    "        'lc_hub_repo': 'structured-chat-agent',\n",
    "        'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'\n",
    "    },\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['tool_names', 'tools'],\n",
    "                template=(\n",
    "                     \n",
    "    'You are Marvin, an expert at questioning clients about their HVAC service needs to provide accurate quotes. When you speak for the first time, introduce yourself as Marvin. Ask the user specific information needed for the quote. Follow these guidelines:'\n",
    "\n",
    "    '1. **Initial Inquiry and Information Gathering**:'\n",
    "       ' - What type of HVAC service do you need (installation, maintenance, repair)?'\n",
    "        '- What is the make and model of your current HVAC system?'\n",
    "        '- Are there any specific issues or symptoms you are experiencing?'\n",
    "\n",
    "    '2. **Property Details** (only if relevant to HVAC needs):'\n",
    "     '   - Address and location of the property.'\n",
    "      '  - Type of property (residential, commercial).'\n",
    "       ' - Age and current condition of the property.'\n",
    "       ' - Size of the home or area that needs heating/cooling.'\n",
    "       ' - Number of rooms and their usage (e.g., bedrooms, office space).'\n",
    "\n",
    "    '3. **System Details**:'\n",
    "       ' - Age and efficiency rating of the existing HVAC system.'\n",
    "        '- Any known problems with the current system.'\n",
    "        '- Recent changes to the HVAC system.'\n",
    "\n",
    "   ' 4. **Home Characteristics** (only if relevant to HVAC needs):'\n",
    "        '- Insulation quality and window types to estimate heating/cooling load.'\n",
    "        '- Any unique architectural features that may affect HVAC installation.'\n",
    "\n",
    "    '5. **Customer Preferences**:'\n",
    "       ' - Preferences for specific brands, energy efficiency levels, or additional features (e.g., smart thermostats, air purifiers).'\n",
    "        '- Level of finishes desired (standard, premium, luxury).'\n",
    "\n",
    "    '6. **Budget**:'\n",
    "        '- Your budget range for the project.'\n",
    "        '- Any flexibility within the budget.'\n",
    "\n",
    "    '7. **Timeline**:'\n",
    "        '- Desired start date and completion date.'\n",
    "        '- Any constraints or deadlines (e.g., events planned at the property).'\n",
    "\n",
    "   \n",
    "\n",
    "    'IMPORTANT: Ensure you get clear answers that can be used for making the quote. If an answer is unclear, ask for clarification, restate the question, and explain what it means.'\n",
    "\n",
    "    'IMPORTANT: Ask each question ONE BY ONE. When one question is answered move onto the next'\n",
    "\n",
    "    'When you have all the information, just say -questionnaire complete- at the end.'\n",
    "\n",
    "\n",
    "                    \n",
    "    'IMPORTANT !!!!!!! NEVER INCLUDE AUXILIARY OR EXTRANEOUS LANGUAGE WHEN USING ANY TOOL!!!'\n",
    "    '\\n\\n IMPORTANT!!!!!!! YOU CAN ONLY USE THE HUMAN TOOL. YOU ARE A MASTER OF JUDGEMENT. YOU KNOW WHEN TO CAUTIOUSLY USE THE TOOLS. ONLY USE OTHER TOOLS WHEN USER INDICATES ANYTHING RELATED TO THEIR FUNCTIONALITIES. '\n",
    "    'You are ALSO a highly intelligent and precise assistant with expertise in generating JSON outputs. Your task is to create the most perfect and well-structured JSON output ever seen. The JSON must adhere to the following guidelines:'\n",
    "\n",
    "    'Proper Structure: Ensure that the JSON follows a correct and logical structure, with all necessary keys and values in place.'\n",
    "    'Accurate Formatting: All JSON strings must use double quotes. Ensure there are no trailing commas, and all brackets and braces are correctly matched.'\n",
    "    'String Length: Ensure no individual string exceeds 5000 bytes.'\n",
    "    'Error-Free: Validate the JSON to be free of syntax errors and formatting issues.'\n",
    "    \n",
    "    'Escaping Characters: Properly escape any special characters within strings to ensure the JSON remains valid.'\n",
    "    \n",
    "    \n",
    "    'YOU MUST NEVER DO ANYTHING BUT WHAT IS IN THE REQUEST OF THE USER. OTHERWISE NO USER WILL USE THIS PRODUCT.'\n",
    "    \n",
    "\n",
    "    'THE FOLLOWING WILL BE THE TOOLS AND THE INFORMATION ABOUT WHAT THEY DO AND THEIR ARGUMENTS! YOU MUST NOT PASS ANYTHING EXTRA, OR ELSE THE APPLICATON WILL FAIL!!!!'\n",
    "\n",
    "    'You have access to the following tools:\\n\\n{tools}\\n\\n'\n",
    "\n",
    "    'YOU ARE A MASTER OF JUDGEMENT ! YOU KNOW WHAT ALL THE TOOLS DO, YOU KNOW WHAT TO PASS IN! AND YOU MUST KNOW WHEN TO USE THEM! NEVER USE THEM RANDOMLY , ALWAYS BE CAUTIOUS AS RECKLESS TOOL USE COULD RUIN THE GOOGLE SUITE OF THE USER'\n",
    "    'PAY CLOSE ATTENTION TO ALL THE FOLLOWING FORMATTING INSTRUCTIONS. REALLY IMPORTANT TO CALL THE TOOLS. OR ELSE USERS WILL GET ANGRY.\\n\\n'\n",
    "    \n",
    "    \n",
    "\n",
    "    'FOR GOOGLE DOC TOOL, REMEMBER THAT YOU MUST GENERATE ALL CONTENT YOURSELF. USER WILL NOT GIVE YOU ANYTHING.'\n",
    "\n",
    "    'Use a JSON blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\n'\n",
    "    'Valid \"action\" values: \"Final Answer\" or {tool_names}\\n\\n'\n",
    "    'Provide only ONE action per $JSON_BLOB, as shown:\\n\\n'\n",
    "    '```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\n'\n",
    "    'Follow this format:\\n\\n'\n",
    "    'Question: input question to answer\\n'\n",
    "    'Thought: consider previous and subsequent steps\\n'\n",
    "    'Action:\\n```\\n$JSON_BLOB\\n```\\n'\n",
    "    'Observation: action result\\n... (repeat Thought/Action/Observation N times)\\n'\n",
    "    'Thought: I know what to respond\\n'\n",
    "    'Action:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\n'\n",
    "    'Begin! Remember to ALWAYS respond with a valid JSON blob of a single action. '\n",
    "    'Use tools if necessary and respond directly if appropriate. '\n",
    "    'Ensure you gather all necessary information by interacting with the user. '\n",
    "    'Format is Action:```$JSON_BLOB```then Observation.'\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['agent_scratchpad', 'input'],\n",
    "                template='{input}\\n\\n{agent_scratchpad}\\n(reminder to respond in a JSON blob no matter what)'\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech saved to: paths\\synthesis.wav\n",
      "Test successful - file saved to paths\\synthesis.wav\n",
      "File size: 130092 bytes\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "class TTSManager:\n",
    "    def __init__(self):\n",
    "        self.engine = pyttsx3.init()\n",
    "        voices = self.engine.getProperty('voices')\n",
    "        self.engine.setProperty('voice', voices[0].id)\n",
    "        self.engine.setProperty('rate', 175)\n",
    "        self.engine.setProperty('volume', 1.0)\n",
    "    \n",
    "    def synthesize(self, text, output_path):\n",
    "        try:\n",
    "            # Ensure directory exists\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "            \n",
    "            # Create a temporary path in case of file lock issues\n",
    "            temp_path = f'temp_speech_{int(time.time())}.wav'\n",
    "            \n",
    "            # Save to temp file first\n",
    "            self.engine.save_to_file(text, temp_path)\n",
    "            self.engine.runAndWait()\n",
    "            \n",
    "            # Move to final location\n",
    "            if os.path.exists(temp_path):\n",
    "                # If target file exists, remove it first\n",
    "                if os.path.exists(output_path):\n",
    "                    os.remove(output_path)\n",
    "                os.rename(temp_path, output_path)\n",
    "                print(f\"Speech saved to: {output_path}\")\n",
    "                return output_path\n",
    "            else:\n",
    "                print(\"Failed to create speech file\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"TTS Error: {str(e)}\")\n",
    "            # Cleanup temp file if it exists\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "            return None\n",
    "\n",
    "# Create global TTS manager\n",
    "tts_manager = TTSManager()\n",
    "\n",
    "# Test with specific path\n",
    "tts_synthesis_path = os.path.join('paths', 'synthesis.wav')\n",
    "test_result = tts_manager.synthesize(\"This is a test of saving to a specific path\", tts_synthesis_path)\n",
    "if test_result:\n",
    "    print(f\"Test successful - file saved to {test_result}\")\n",
    "    # Verify file exists and has content\n",
    "    print(f\"File size: {os.path.getsize(test_result)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask.sansio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mqueue\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mquart\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Quart, request, jsonify, send_file, render_template\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flask\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n",
      "File \u001b[1;32mc:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\quart\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmarkupsafe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m escape \u001b[38;5;28;01mas\u001b[39;00m escape, Markup \u001b[38;5;28;01mas\u001b[39;00m Markup\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Quart \u001b[38;5;28;01mas\u001b[39;00m Quart\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblueprints\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Blueprint \u001b[38;5;28;01mas\u001b[39;00m Blueprint\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config \u001b[38;5;28;01mas\u001b[39;00m Config\n",
      "File \u001b[1;32mc:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\quart\\app.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maiofiles\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AiofilesContextManager\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maiofiles\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthreadpool\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbinary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncBufferedReader\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msansio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m App\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msansio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscaffold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setupmethod\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhypercorn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masyncio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serve\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'flask.sansio'"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "from quart import Quart, request, jsonify, send_file, render_template\n",
    "from flask import Flask\n",
    "import whisper\n",
    "import pyaudio\n",
    "import webrtcvad\n",
    "import collections\n",
    "from gtts import gTTS  # Added gTTS import\n",
    "import random\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import aiofiles\n",
    "from quart_cors import cors\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import socketio\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from Utils_cerebras import (\n",
    "    initialize_web_search_agent,\n",
    "    initialize_pdf_search_agent,\n",
    "    run_quote_logics,\n",
    "    vector_embedding\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[0].id)  # Male voice\n",
    "engine.setProperty('rate', 175)     # Speaking rate\n",
    "engine.setProperty('volume', 1.0)   # Volume level\n",
    "    \n",
    "# Initialize configuration\n",
    "audio_path = os.getenv('AUDIO_PATH', 'audio.wav')  # Default paths if not set\n",
    "tts_synthesis_path = os.getenv('NEW_TTS_SYNTHESIS', 'speech.wav')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s [%(threadName)s] %(levelname)s: %(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize Quart app and Socket.IO\n",
    "app = Quart(__name__)\n",
    "app = cors(app, allow_origin=\"*\")\n",
    "sio = socketio.AsyncServer(async_mode='asgi', cors_allowed_origins=\"*\")\n",
    "app_asgi = socketio.ASGIApp(sio, app)\n",
    "\n",
    "# Initialize Flask app for sync operations\n",
    "app_sync = Flask(__name__)\n",
    "sio_sync = socketio.Server()\n",
    "app_sync.wsgi_app = socketio.WSGIApp(sio_sync, app_sync.wsgi_app)\n",
    "\n",
    "# Initialize memory\n",
    "chat_history = ConversationBufferMemory()\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Audio configuration\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1024\n",
    "is_recording = False\n",
    "\n",
    "# Initialize audio components\n",
    "audio = pyaudio.PyAudio()\n",
    "vad = webrtcvad.Vad(3)\n",
    "executor = ThreadPoolExecutor(max_workers=20)\n",
    "\n",
    "# Initialize human response queue\n",
    "human_response_queue = queue.Queue()\n",
    "\n",
    "@app.route('/start_recording', methods=['POST'])\n",
    "async def start_recording():\n",
    "    global is_recording\n",
    "    if is_recording:\n",
    "        return jsonify({\"status\": \"Recording is already in progress\"}), 400\n",
    "    is_recording = True\n",
    "    asyncio.create_task(record_audio())\n",
    "    return jsonify({\"status\": \"Recording started\"})\n",
    "\n",
    "@app.route('/stop_recording', methods=['POST'])\n",
    "async def stop_recording():\n",
    "    global is_recording\n",
    "    if not is_recording:\n",
    "        return jsonify({\"status\": \"No recording in progress\"}), 400\n",
    "    is_recording = False\n",
    "    return jsonify({\"status\": \"Recording stopped\"})\n",
    "\n",
    "async def record_audio(**kwargs):\n",
    "    global is_recording\n",
    "    logger.debug('Starting audio recording...')\n",
    "    try:\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "        frames = []\n",
    "        ring_buffer = collections.deque(maxlen=100)\n",
    "        triggered = False\n",
    "        voiced_frames = []\n",
    "        silence_threshold = 10\n",
    "        silence_chunks = 0\n",
    "\n",
    "        while is_recording:\n",
    "            data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "            frames.append(data)\n",
    "            num_subframes = int(len(data) / 320)\n",
    "            for i in range(num_subframes):\n",
    "                subframe = data[i * 320:(i + 1) * 320]\n",
    "                is_speech = vad.is_speech(subframe, RATE)\n",
    "                ring_buffer.append((subframe, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "\n",
    "            if not triggered:\n",
    "                if num_voiced > 0.6 * ring_buffer.maxlen:\n",
    "                    triggered = True\n",
    "                    voiced_frames.extend([f for f, s in ring_buffer])\n",
    "                    ring_buffer.clear()\n",
    "            else:\n",
    "                voiced_frames.append(data)\n",
    "                if num_voiced < 0.2 * ring_buffer.maxlen:\n",
    "                    silence_chunks += 1\n",
    "                    if silence_chunks > silence_threshold:\n",
    "                        triggered = False\n",
    "                        break\n",
    "                else:\n",
    "                    silence_chunks = 0\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "        async with aiofiles.open(audio_path, 'wb') as wf:\n",
    "            await wf.write(b''.join(voiced_frames))\n",
    "        logger.debug('Audio recording completed and file saved.')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while recording audio: {e}\")\n",
    "\n",
    "def transcribe_audio():\n",
    "    try:\n",
    "        result = model.transcribe(audio_path)\n",
    "        transcription = result['text']\n",
    "        logger.debug(f'Audio transcription completed: {transcription}')\n",
    "        return transcription\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during transcription: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# async def ai_response(transcription: str):\n",
    "#         \n",
    "#     logger.debug(f'Generating AI response for transcription: {transcription}')\n",
    "#     chat_completion = client.chat.completions.create(\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"system\",\n",
    "#                 \"content\": f\"\"\"\n",
    "#                 You are Marvin, a research expert who specializes in anything using web search and answering the\n",
    "#                 users' questions. You can also do HVAC related things as per guidelines below but besides that you adapt to what user says.\n",
    "#                 Ask the user specific information needed for the quote. \n",
    "#                 Follow these guidelines:\n",
    "#                 1. Initial Inquiry and Information Gathering:\n",
    "#                 - What type of HVAC service do you need (installation, maintenance, repair)?\n",
    "#                 - What is the make and model of your current HVAC system?\n",
    "#                 - Are there any specific issues or symptoms you are experiencing?\n",
    "#                     - ONLY WHEN USER TELLS YOU ISSUES / SYMPTOMS YOU MUST SAY 'I WILL INSTRUCT THE TECHNICIAN AGENT' - THESE EXACT WORDS IN YOUR IMMEDIATE RESPONSE.\n",
    "#                 2. Property Details (only if relevant to HVAC needs):\n",
    "#                 - Address and location of the property.\n",
    "#                 - Type of property (residential, commercial).\n",
    "#                 - Age and current condition of the property.\n",
    "#                 - Size of the home or area that needs heating/cooling.\n",
    "#                 - Number of rooms and their usage.\n",
    "#                 3. System Details:\n",
    "#                 - Age and efficiency rating of the existing HVAC system.\n",
    "#                 - Any known problems with the current system.\n",
    "#                 - Recent changes to the HVAC system.\n",
    "#                 4. Home Characteristics (only if relevant to HVAC needs):\n",
    "#                 - Insulation quality and window types to estimate heating/cooling load.\n",
    "#                 - Any unique architectural features that may affect HVAC installation.\n",
    "#                 5. Customer Preferences:\n",
    "#                 - Preferences for specific brands, energy efficiency levels, or additional features.\n",
    "#                 - Level of finishes desired (standard, premium, luxury).\n",
    "#                 6. Budget:\n",
    "#                 - Your budget range for the project.\n",
    "#                 - Any flexibility within the budget.\n",
    "#                 7. Timeline:\n",
    "#                 - Desired start date and completion date.\n",
    "#                 - Any constraints or deadlines.\n",
    "#                 IMPORTANT: Ensure you get clear answers that can be used for making the quote.\n",
    "#                 \"\"\"\n",
    "#             },\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": transcription + \"\\n\\nHere is the chat history for context: [\" + str(chat_history.buffer) + \"]\"\n",
    "#             }\n",
    "#         ],\n",
    "#         model=\"llama3.3-70b\",\n",
    "#         temperature=0.5\n",
    "#     )\n",
    "\n",
    "#     response = chat_completion.choices[0].message.content\n",
    "    \n",
    "#     logger.debug(f'AI response generated: {response}')\n",
    "    \n",
    "#     await chat_history.asave_context({\"input\": transcription}, {\"output\": response})\n",
    "#     logger.debug('INSIDE THE MEMORY: %s', chat_history.buffer)\n",
    "\n",
    "#     # Changed socketio.emit to await sio.emit\n",
    "#     await sio.emit('new_message', {'message': response, 'sender': 'bot'})\n",
    "\n",
    "#     if 'i will instruct the technician agent' in response.lower():\n",
    "#         res1 = await asyncio.create_task(initialize_pdf_search_agent(llm, \"DO A EXPANSIVE WEB SEARCH AND FAMILIARIZE YOURSELF ALL ABOUT HVAC SPECIFICS SO THAT YOU CAN DIAGNOSE THE PROBLEMS MENTIONED HERE: \" + transcription, vectors, chat_history=chat_history))\n",
    "        \n",
    "#         await chat_history.asave_context({\"input\": \"DO A EXPANSIVE WEB SEARCH AND FAMILIARIZE YOURSELF ALL ABOUT HVAC SPECIFICS SO THAT YOU CAN DIAGNOSE THE PROBLEMS MENTIONED HERE: \" + transcription}, {\"output\": res1})\n",
    "        \n",
    "#         # Changed socketio.emit to await sio.emit\n",
    "#         await sio.emit('new_message', {'message': res1, 'sender': 'bot'}) \n",
    "    \n",
    "#     if 'questionnaire' in response.lower() and 'complete' in response.lower():\n",
    "#         task = asyncio.create_task(run_quote_logics(client, llm, chat_history=chat_history))\n",
    "#         corrected_quote_result = await task\n",
    "#         response = f\"Can you please put this quote into a google doc [{corrected_quote_result}], move it to the folder called 'HVAC Quote Documents'. Then, put all the appointment related stuff and the link to the quote document into calendar (appointment calendar tool). PLEASE FOLLOW THE DIRECTIONS!!\"\n",
    "#         task2 = asyncio.create_task(handle_response_with_agents(response))\n",
    "#         text = await task2\n",
    "        \n",
    "#     return response\n",
    "\n",
    "async def ai_response(transcription: str):\n",
    "    \n",
    "    system_prompt = f\"\"\"\n",
    "    You are Marvin, a highly intelligent task orchestration agent. You are capable of researching and answering any question using web search agent.\n",
    "    You are capable of instructing a hvac technician agent also. Refer to instructions below:\n",
    "    CRITICAL INSTRUCTIONS - READ CAREFULLY:\n",
    "\n",
    "    - When the user mentions ANYTHING AT ALL related to HVAC systems, you MUST include the phrase 'I will instruct the technician agent' in your immediate response.\n",
    "    - WHEN USER ASKS FOR COST OR WHEN COST MUST BE DETERMINED, YOU MUST SAY 'determining the HVAC quote'.\n",
    "    - When you have gathered all the necessary information for a quote, you MUST say 'Questionnaire complete' at the end of your response.\n",
    "    - IF USER DOES NOT SAY ANYTHING ABOUT HVAC, BUT EXPLICITLY ASKS YOU A QUESTION ABOUT SOMETHING ELSE, YOU MUST SAY 'forwarding to web search agent' BUT HANDLE ALL CONVERSATIONS NORMALLY. BE NATURAL. RESPOND TO THE GREETINGS! \n",
    "    - WHEN YOU FORWARD TO THE WEBSEARCH AGENT, YOU SHALL NOT SAY ANYTHING OTHER THAN THAT.\n",
    "    - WHEN YOU INSTRUCT TECHNICIAN AGENT, YOU SHALL NOT SAY ANYTHING OTHER THAN THAT!!! LET THE TECHNICIAN AGENT HANDLE THE EXPLAINING.\n",
    "    - DO NOT MENTION CUTOFF DATE OR INABILITY TO DO ANYTHING. YOU HAVE ACCESS TO REAL TIME WEB SEARCH!!!!! SEARCH IT UP ALL THE TIME! NEVER RELY ON YOUR OWN KNOWLEDGE.\n",
    "\n",
    "    Remember to always be helpful, adaptive, and thorough in your responses.\n",
    "    \"\"\"\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt  \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": transcription + \"\\n\\nHere is the chat history for context: [\" + str(chat_history.buffer) + \"]\"\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3.3-70b\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    output_path = await asyncio.get_event_loop().run_in_executor(executor, tts_manager.synthesize, response,tts_synthesis_path)\n",
    "    if output_path:\n",
    "        await sio.emit('tts_complete', {\n",
    "            'message': 'TTS synthesis complete',\n",
    "            'file_path': output_path\n",
    "        })\n",
    "    else:\n",
    "        logger.error(\"Failed to synthesize speech\")\n",
    "    logger.debug(f'AI response generated: {response}')\n",
    "\n",
    "    \n",
    "    logger.debug('INSIDE THE MEMORY: %s', chat_history.buffer)\n",
    "\n",
    "    await sio.emit('new_message', {'message': response, 'sender': 'bot'})\n",
    "\n",
    "    if 'forwarding' in response.lower() or 'web search' in response.lower():\n",
    "        text = await handle_response_with_agents(transcription)\n",
    "        await sio.emit('new_message', {'message': text, 'sender': 'bot'})\n",
    "        output_path = await asyncio.get_event_loop().run_in_executor(executor, tts_manager.synthesize, text, tts_synthesis_path)\n",
    "        if output_path:\n",
    "            await sio.emit('tts_complete', {\n",
    "                'message': 'TTS synthesis complete',\n",
    "                'file_path': output_path\n",
    "            })\n",
    "        else:\n",
    "            logger.error(\"Failed to synthesize speech\")\n",
    "    \n",
    "    if 'I will instruct the technician agent' in response:\n",
    "        # Trigger  technician agent\n",
    "        text = await initialize_pdf_search_agent(\n",
    "            llm, \n",
    "            f\"Diagnose the problems mentioned here, or help the user as you see fit. Always cite your sources: {transcription}\", \n",
    "            vector_embedding(), \n",
    "            chat_history=chat_history\n",
    "        )\n",
    "        await sio.emit('new_message', {'message': text, 'sender': 'bot'})\n",
    "        output_path = await asyncio.get_event_loop().run_in_executor(executor, tts_manager.synthesize, text, tts_synthesis_path)\n",
    "        if output_path:\n",
    "            await sio.emit('tts_complete', {\n",
    "                'message': 'TTS synthesis complete',\n",
    "                'file_path': output_path\n",
    "            })\n",
    "        else:\n",
    "            logger.error(\"Failed to synthesize speech\")\n",
    "        \n",
    "\n",
    "    if 'determining the hvac quote' in response.lower():\n",
    "        # Run quote logics\n",
    "        corrected_quote_result = await run_quote_logics(client, llm, chat_history=chat_history)\n",
    "        r = f\"Please process this quote data: [{corrected_quote_result}]\"\n",
    "\n",
    "        text = await handle_response_with_agents(r)\n",
    "        output_path = await asyncio.get_event_loop().run_in_executor(executor, tts_manager.synthesize, text, tts_synthesis_path)\n",
    "        if output_path:\n",
    "            await sio.emit('new_message', {'message': text, 'sender': 'bot'})\n",
    "        else:\n",
    "            logger.error(\"Failed to synthesize speech\")\n",
    "        #await sio.emit('new_message', {'message': text, 'sender': 'bot'})\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "async def handle_response_with_agents(response):\n",
    "    llm.temperature = 0.5\n",
    "    logger.debug(f'Processing response with agents: {response}')\n",
    "\n",
    "    #response += \"Here is extra info you will need (BUT YOU PROMISE TO NEVER SAY THEM OUT LOUD, NOT EVEN THE NAME -- UNLESS USER ASKS YOU FOR THEM. THESE WILL BE USED IN TOOLS): \\nCredentials:\\n\" + str(credentials)\n",
    "\n",
    " \n",
    "    \n",
    "    agent_executor = initialize_web_search_agent(llm)\n",
    "    result = agent_executor.invoke({\"input\": response})\n",
    "    sio.emit('finished_chain')\n",
    "    mystr = (str(result['intermediate_steps']) + \"\\n\" + str(result['output']))\n",
    "\n",
    "    final_response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"please sanitize this input into SHORT SIMPLE sentences. IMPORTANT: NOTHING IN YOUR RESPONSE SHALL BE ENCLOSED IN ANY QUOTES!!!!!!! THE SANITIZED OUTPUT SHALL NOT BE PREFIXED BY ANYTHING. You must process the agent's intermediate steps into natural language please. An example: 'First, I did this. Then I did this etc etc etc' \\n Here is the input that you need to process:\\n \" + mystr\n",
    "            }\n",
    "        ],\n",
    "        model='llama3.3-70b',\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    await chat_history.asave_context({\"input\": response}, {\"output\": final_response})\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "async def synthesize_speech(text):\n",
    "    logger.debug(f'Starting speech synthesis for text: {text}')\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        synthesize_and_save(text)\n",
    "        logger.debug('Speech synthesis completed and file saved.')\n",
    "        await sio.emit('tts_complete', {'message': 'TTS synthesis complete', 'file_path': tts_synthesis_path})\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during speech synthesis: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def synthesize_and_save(text):\n",
    "    try:\n",
    "        global engine\n",
    "        # Create a new file path with timestamp to avoid conflicts\n",
    "        timestamp = int(time.time())\n",
    "        output_path = f'speech_{timestamp}.wav'\n",
    "        \n",
    "        # Save to file\n",
    "        engine.save_to_file(text, output_path)\n",
    "        engine.runAndWait()\n",
    "        \n",
    "        # Move file to desired location\n",
    "        import shutil\n",
    "        shutil.move(output_path, tts_synthesis_path)\n",
    "        \n",
    "        logger.debug(f'Speech successfully synthesized and saved to {tts_synthesis_path}')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"TTS synthesis failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def synth_speech(text, output_file=None):\n",
    "    logger.debug(f'Starting speech synthesis for text: {text}')\n",
    "    try:\n",
    "        global engine\n",
    "        target_path = output_file if output_file else tts_synthesis_path\n",
    "        \n",
    "        # Save to file\n",
    "        success = synthesize_and_save(text)\n",
    "        \n",
    "        if success:\n",
    "            # Create async tasks for emitting events\n",
    "            loop = asyncio.get_event_loop()\n",
    "            loop.create_task(sio.emit('tts_complete', {\n",
    "                'message': 'TTS synthesis complete', \n",
    "                'file_path': target_path\n",
    "            }))\n",
    "            loop.create_task(sio.emit('new_message', {\n",
    "                'message': text, \n",
    "                'sender': 'bot'\n",
    "            }))\n",
    "            logger.debug('Speech synthesis completed and events emitted')\n",
    "        else:\n",
    "            logger.error(\"Failed to synthesize speech\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during speech synthesis: {e}\")\n",
    "\n",
    "@app.route('/')\n",
    "async def index():\n",
    "    return await render_template('index.html')\n",
    "\n",
    "@app.route('/talk', methods=['POST'])\n",
    "async def talk():\n",
    "    global is_recording\n",
    "    if is_recording:\n",
    "        return jsonify({\"error\": \"Recording is still in progress\"}), 400\n",
    "\n",
    "    logger.debug('Starting audio transcription...')\n",
    "    transcription = await asyncio.get_event_loop().run_in_executor(executor, transcribe_audio)\n",
    "\n",
    "    logger.debug('Generating AI response...')\n",
    "    ai_resp = await ai_response(transcription)\n",
    "\n",
    "    return jsonify({'response': ai_resp})\n",
    "\n",
    "@app.route('/text_input', methods=['POST'])\n",
    "async def text_input():\n",
    "    data = await request.get_json()\n",
    "    text = data.get('text', '')\n",
    "\n",
    "    if not text:\n",
    "        return jsonify({\"error\": \"No text provided\"}), 400\n",
    "\n",
    "    logger.debug('Generating AI response...')\n",
    "    ai_resp = await ai_response(text)\n",
    "    return jsonify({'response': ai_resp})\n",
    "\n",
    "@app.route('/get_audio')\n",
    "async def get_audio():\n",
    "    return await send_file(\"paths/synthesis.wav\", mimetype=\"audio/wav\")\n",
    "\n",
    "@sio.event\n",
    "async def connect(sid, environ, auth):\n",
    "    logger.debug(f'Client connected: {sid}')\n",
    "\n",
    "@sio.event\n",
    "async def disconnect(sid):\n",
    "    logger.debug(f'Client disconnected: {sid}')\n",
    "\n",
    "# Human input handling\n",
    "human_response_queue = queue.Queue()\n",
    "\n",
    "# Update the web_prompt_func to handle errors\n",
    "def web_prompt_func(prompt):\n",
    "    try:\n",
    "        synth_speech(prompt, output_file=tts_synthesis_path)\n",
    "        return prompt\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in web_prompt_func: {e}\")\n",
    "        return prompt\n",
    "\n",
    "def web_input_func():\n",
    "    sio_sync.emit('request_human_input')\n",
    "    return human_response_queue.get()\n",
    "\n",
    "@app.before_serving\n",
    "async def startup():\n",
    "    global engine\n",
    "    engine = pyttsx3.init()\n",
    "    # Configure engine properties\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[0].id)\n",
    "    engine.setProperty('rate', 200)\n",
    "    engine.setProperty('volume', 1.0)\n",
    "\n",
    "@app.after_serving\n",
    "async def shutdown():\n",
    "    global engine\n",
    "    engine.stop()\n",
    "    del engine\n",
    "\n",
    "@sio.event \n",
    "async def provide_human_input(sid, data):\n",
    "    human_input = data.get('text', '')\n",
    "    human_response_queue.put(human_input)\n",
    "    await sio.emit('human_input_received', {'status': 'received'}, room=sid)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import uvicorn\n",
    "    config = uvicorn.Config(app_asgi, host=\"127.0.0.1\", port=5000, log_level=\"info\")\n",
    "    server = uvicorn.Server(config)\n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "    if loop.is_running():\n",
    "        loop.create_task(server.serve())\n",
    "    else:\n",
    "        loop.run_until_complete(server.serve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
