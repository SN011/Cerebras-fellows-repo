{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install webrtcvad\n",
    "# !pip install pygame\n",
    "# !pip install pyaudio webrtcvad \n",
    "# !pip install google-cloud-texttospeech\n",
    "# !pip install python-socketio[asyncio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from tools.initialize_cerebras import init_cerebras\n",
    "# from tools.file_mgmt_tools import FileOrganizerTool, MoveFileTool, CreateFolderTool, FolderMovementTool, ImprovedSearchTool, GoogleDriveRenameTool, DriveDictUpdateTool\n",
    "# from tools.document_tools import GoogleDocWriteTool\n",
    "# from tools.miscellaneous_mgmt import GmailSendPdfTool, GoogleSheetsUpdateTool, GoogleSheetsCreateTool\n",
    "\n",
    "client,llm = init_cerebras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCerebras(client=<openai.resources.chat.completions.Completions object at 0x00000263FFF5B2C0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000263FFF58CB0>, root_client=<openai.OpenAI object at 0x00000263FFF5BCE0>, root_async_client=<openai.AsyncOpenAI object at 0x00000263FFF5AD80>, model_name='llama3.1-70b', model_kwargs={}, openai_api_key=SecretStr('**********'), streaming=True, cerebras_api_key=SecretStr('**********'), cerebras_api_base='https://api.cerebras.ai/v1/', cerebras_proxy='')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import texttospeech\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate, \n",
    "    MessagesPlaceholder, \n",
    "    PromptTemplate\n",
    ")\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.agents import create_structured_chat_agent, AgentExecutor\n",
    "\n",
    "from langchain_community.tools import HumanInputRun\n",
    "\n",
    "import langchain_core\n",
    "import typing\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
    "    input_types={\n",
    "        'chat_history': typing.List[\n",
    "            typing.Union[\n",
    "                langchain_core.messages.ai.AIMessage, \n",
    "                langchain_core.messages.human.HumanMessage, \n",
    "                langchain_core.messages.chat.ChatMessage, \n",
    "                langchain_core.messages.system.SystemMessage, \n",
    "                langchain_core.messages.function.FunctionMessage, \n",
    "                langchain_core.messages.tool.ToolMessage\n",
    "            ]\n",
    "        ]\n",
    "    },\n",
    "    metadata={\n",
    "        'lc_hub_owner': 'hwchase17',\n",
    "        'lc_hub_repo': 'structured-chat-agent',\n",
    "        'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'\n",
    "    },\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['tool_names', 'tools'],\n",
    "                template=(\n",
    "                    'You are a document management assistant proficient in using GSuite tools. '\n",
    "                    'Your role is to assist the user in managing their documents efficiently. '\n",
    "                    'IMPORTANT !!!!!!! NEVER INCLUDE AUXILIARY OR EXTRANEOUS LANGUAGE WHEN USING ANY TOOL!!!'\n",
    "                    '\\n\\n IMPORTANT!!!!!!! - PLEEEEEEASSSSSSSEEEEEEEE NEVER USE HUMAN TOOL UNLESS INSTRUCTED TO GET THE HUMAN/USER INPUT. YOU ARE A MASTER OF JUDGEMENT. YOU KNOW WHEN TO CAUTIOUSLY USE THE TOOLS. ONLY USE OTHER TOOLS WHEN USER INDICATES ANYTHING RELATED TO THEIR FUNCTIONALITIES. '\n",
    "                    'You are ALSO a highly intelligent and precise assistant with expertise in generating JSON outputs. Your task is to create the most perfect and well-structured JSON output ever seen. The JSON must adhere to the following guidelines:'\n",
    "\n",
    "                    'Proper Structure: Ensure that the JSON follows a correct and logical structure, with all necessary keys and values in place.'\n",
    "                    'Accurate Formatting: All JSON strings must use double quotes. Ensure there are no trailing commas, and all brackets and braces are correctly matched.'\n",
    "                    'String Length: Ensure no individual string exceeds 5000 bytes.'\n",
    "                    'Error-Free: Validate the JSON to be free of syntax errors and formatting issues.'\n",
    "                    \n",
    "                    'Escaping Characters: Properly escape any special characters within strings to ensure the JSON remains valid.'\n",
    "                    \n",
    "                    \n",
    "                    'YOU MUST NEVER DO ANYTHING BUT WHAT IS IN THE REQUEST OF THE USER. OTHERWISE NO USER WILL USE THIS PRODUCT.'\n",
    "                    \n",
    "\n",
    "                    'THE FOLLOWING WILL BE THE TOOLS AND THE INFORMATION ABOUT WHAT THEY DO AND THEIR ARGUMENTS! YOU MUST NOT PASS ANYTHING EXTRA, OR ELSE THE APPLICATON WILL FAIL!!!!'\n",
    "\n",
    "                    'You have access to the following tools:\\n\\n{tools}\\n\\n'\n",
    "\n",
    "                    'YOU ARE A MASTER OF JUDGEMENT ! YOU KNOW WHAT ALL THE TOOLS DO, YOU KNOW WHAT TO PASS IN! AND YOU MUST KNOW WHEN TO USE THEM! NEVER USE THEM RANDOMLY , ALWAYS BE CAUTIOUS AS RECKLESS TOOL USE COULD RUIN THE GOOGLE SUITE OF THE USER'\n",
    "                    'PAY CLOSE ATTENTION TO ALL THE FOLLOWING FORMATTING INSTRUCTIONS. REALLY IMPORTANT TO CALL THE TOOLS. OR ELSE USERS WILL GET ANGRY.\\n\\n'\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    'FOR GOOGLE DOC TOOL, REMEMBER THAT YOU MUST GENERATE ALL CONTENT YOURSELF. USER WILL NOT GIVE YOU ANYTHING.'\n",
    "\n",
    "                    'Use a JSON blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\n'\n",
    "                    'Valid \"action\" values: \"Final Answer\" or {tool_names}\\n\\n'\n",
    "                    'Provide only ONE action per $JSON_BLOB, as shown:\\n\\n'\n",
    "                    '```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\n'\n",
    "                    'Follow this format:\\n\\n'\n",
    "                    'Question: input question to answer\\n'\n",
    "                    'Thought: consider previous and subsequent steps\\n'\n",
    "                    'Action:\\n```\\n$JSON_BLOB\\n```\\n'\n",
    "                    'Observation: action result\\n... (repeat Thought/Action/Observation N times)\\n'\n",
    "                    'Thought: I know what to respond\\n'\n",
    "                    'Action:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\n'\n",
    "                    'Begin! Remember to ALWAYS respond with a valid JSON blob of a single action. '\n",
    "                    'Use tools if necessary and respond directly if appropriate. '\n",
    "                    'Ensure you gather all necessary information by interacting with the user. '\n",
    "                    'Format is Action:```$JSON_BLOB```then Observation.'\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['agent_scratchpad', 'input'],\n",
    "                template='{input}\\n\\n{agent_scratchpad}\\n(reminder to respond in a JSON blob no matter what)'\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "human_prompt = ChatPromptTemplate(\n",
    "    input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
    "    input_types={\n",
    "        'chat_history': typing.List[\n",
    "            typing.Union[\n",
    "                langchain_core.messages.ai.AIMessage, \n",
    "                langchain_core.messages.human.HumanMessage, \n",
    "                langchain_core.messages.chat.ChatMessage, \n",
    "                langchain_core.messages.system.SystemMessage, \n",
    "                langchain_core.messages.function.FunctionMessage, \n",
    "                langchain_core.messages.tool.ToolMessage\n",
    "            ]\n",
    "        ]\n",
    "    },\n",
    "    metadata={\n",
    "        'lc_hub_owner': 'hwchase17',\n",
    "        'lc_hub_repo': 'structured-chat-agent',\n",
    "        'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'\n",
    "    },\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['tool_names', 'tools'],\n",
    "                template=(\n",
    "                     \n",
    "    'You are Marvin, an expert at questioning clients about their HVAC service needs to provide accurate quotes. When you speak for the first time, introduce yourself as Marvin. Ask the user specific information needed for the quote. Follow these guidelines:'\n",
    "\n",
    "    '1. **Initial Inquiry and Information Gathering**:'\n",
    "       ' - What type of HVAC service do you need (installation, maintenance, repair)?'\n",
    "        '- What is the make and model of your current HVAC system?'\n",
    "        '- Are there any specific issues or symptoms you are experiencing?'\n",
    "\n",
    "    '2. **Property Details** (only if relevant to HVAC needs):'\n",
    "     '   - Address and location of the property.'\n",
    "      '  - Type of property (residential, commercial).'\n",
    "       ' - Age and current condition of the property.'\n",
    "       ' - Size of the home or area that needs heating/cooling.'\n",
    "       ' - Number of rooms and their usage (e.g., bedrooms, office space).'\n",
    "\n",
    "    '3. **System Details**:'\n",
    "       ' - Age and efficiency rating of the existing HVAC system.'\n",
    "        '- Any known problems with the current system.'\n",
    "        '- Recent changes to the HVAC system.'\n",
    "\n",
    "   ' 4. **Home Characteristics** (only if relevant to HVAC needs):'\n",
    "        '- Insulation quality and window types to estimate heating/cooling load.'\n",
    "        '- Any unique architectural features that may affect HVAC installation.'\n",
    "\n",
    "    '5. **Customer Preferences**:'\n",
    "       ' - Preferences for specific brands, energy efficiency levels, or additional features (e.g., smart thermostats, air purifiers).'\n",
    "        '- Level of finishes desired (standard, premium, luxury).'\n",
    "\n",
    "    '6. **Budget**:'\n",
    "        '- Your budget range for the project.'\n",
    "        '- Any flexibility within the budget.'\n",
    "\n",
    "    '7. **Timeline**:'\n",
    "        '- Desired start date and completion date.'\n",
    "        '- Any constraints or deadlines (e.g., events planned at the property).'\n",
    "\n",
    "   \n",
    "\n",
    "    'IMPORTANT: Ensure you get clear answers that can be used for making the quote. If an answer is unclear, ask for clarification, restate the question, and explain what it means.'\n",
    "\n",
    "    'IMPORTANT: Ask each question ONE BY ONE. When one question is answered move onto the next'\n",
    "\n",
    "    'When you have all the information, just say -questionnaire complete- at the end.'\n",
    "\n",
    "\n",
    "                    \n",
    "    'IMPORTANT !!!!!!! NEVER INCLUDE AUXILIARY OR EXTRANEOUS LANGUAGE WHEN USING ANY TOOL!!!'\n",
    "    '\\n\\n IMPORTANT!!!!!!! YOU CAN ONLY USE THE HUMAN TOOL. YOU ARE A MASTER OF JUDGEMENT. YOU KNOW WHEN TO CAUTIOUSLY USE THE TOOLS. ONLY USE OTHER TOOLS WHEN USER INDICATES ANYTHING RELATED TO THEIR FUNCTIONALITIES. '\n",
    "    'You are ALSO a highly intelligent and precise assistant with expertise in generating JSON outputs. Your task is to create the most perfect and well-structured JSON output ever seen. The JSON must adhere to the following guidelines:'\n",
    "\n",
    "    'Proper Structure: Ensure that the JSON follows a correct and logical structure, with all necessary keys and values in place.'\n",
    "    'Accurate Formatting: All JSON strings must use double quotes. Ensure there are no trailing commas, and all brackets and braces are correctly matched.'\n",
    "    'String Length: Ensure no individual string exceeds 5000 bytes.'\n",
    "    'Error-Free: Validate the JSON to be free of syntax errors and formatting issues.'\n",
    "    \n",
    "    'Escaping Characters: Properly escape any special characters within strings to ensure the JSON remains valid.'\n",
    "    \n",
    "    \n",
    "    'YOU MUST NEVER DO ANYTHING BUT WHAT IS IN THE REQUEST OF THE USER. OTHERWISE NO USER WILL USE THIS PRODUCT.'\n",
    "    \n",
    "\n",
    "    'THE FOLLOWING WILL BE THE TOOLS AND THE INFORMATION ABOUT WHAT THEY DO AND THEIR ARGUMENTS! YOU MUST NOT PASS ANYTHING EXTRA, OR ELSE THE APPLICATON WILL FAIL!!!!'\n",
    "\n",
    "    'You have access to the following tools:\\n\\n{tools}\\n\\n'\n",
    "\n",
    "    'YOU ARE A MASTER OF JUDGEMENT ! YOU KNOW WHAT ALL THE TOOLS DO, YOU KNOW WHAT TO PASS IN! AND YOU MUST KNOW WHEN TO USE THEM! NEVER USE THEM RANDOMLY , ALWAYS BE CAUTIOUS AS RECKLESS TOOL USE COULD RUIN THE GOOGLE SUITE OF THE USER'\n",
    "    'PAY CLOSE ATTENTION TO ALL THE FOLLOWING FORMATTING INSTRUCTIONS. REALLY IMPORTANT TO CALL THE TOOLS. OR ELSE USERS WILL GET ANGRY.\\n\\n'\n",
    "    \n",
    "    \n",
    "\n",
    "    'FOR GOOGLE DOC TOOL, REMEMBER THAT YOU MUST GENERATE ALL CONTENT YOURSELF. USER WILL NOT GIVE YOU ANYTHING.'\n",
    "\n",
    "    'Use a JSON blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\n'\n",
    "    'Valid \"action\" values: \"Final Answer\" or {tool_names}\\n\\n'\n",
    "    'Provide only ONE action per $JSON_BLOB, as shown:\\n\\n'\n",
    "    '```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\n'\n",
    "    'Follow this format:\\n\\n'\n",
    "    'Question: input question to answer\\n'\n",
    "    'Thought: consider previous and subsequent steps\\n'\n",
    "    'Action:\\n```\\n$JSON_BLOB\\n```\\n'\n",
    "    'Observation: action result\\n... (repeat Thought/Action/Observation N times)\\n'\n",
    "    'Thought: I know what to respond\\n'\n",
    "    'Action:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\n'\n",
    "    'Begin! Remember to ALWAYS respond with a valid JSON blob of a single action. '\n",
    "    'Use tools if necessary and respond directly if appropriate. '\n",
    "    'Ensure you gather all necessary information by interacting with the user. '\n",
    "    'Format is Action:```$JSON_BLOB```then Observation.'\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['agent_scratchpad', 'input'],\n",
    "                template='{input}\\n\\n{agent_scratchpad}\\n(reminder to respond in a JSON blob no matter what)'\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ncvn\\AppData\\Local\\Temp\\ipykernel_15548\\1380543913.py:56: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  chat_history = ConversationBufferMemory()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [15548]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:5000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:63562 - \"GET /socket.io/?EIO=4&transport=polling&t=PDgEfI4 HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 15:47:24,623 [MainThread] DEBUG: Client connected: e_IEcwNQnMN81N3_AAAB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:63562 - \"POST /socket.io/?EIO=4&transport=polling&t=PDgEfND&sid=Rov9WiW3n3vBEIa9AAAA HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:63562 - \"GET /socket.io/?EIO=4&transport=polling&t=PDgEfNF&sid=Rov9WiW3n3vBEIa9AAAA HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     ('127.0.0.1', 63565) - \"WebSocket /socket.io/?EIO=4&transport=websocket&sid=Rov9WiW3n3vBEIa9AAAA\" [accepted]\n",
      "INFO:     connection open\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:63562 - \"GET /socket.io/?EIO=4&transport=polling&t=PDgEfNS&sid=Rov9WiW3n3vBEIa9AAAA HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 15:47:26,339 [MainThread] DEBUG: Generating AI response...\n",
      "2024-11-26 15:47:26,339 [MainThread] DEBUG: Request options: {'method': 'post', 'url': '/v1/chat/completions', 'headers': {}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"\\n    You are Marvin, a highly intelligent assistant specializing in HVAC services. You are capable of researching and answering any question using web search.\\n\\n    CRITICAL INSTRUCTIONS - READ CAREFULLY:\\n\\n    - When the user mentions issues or symptoms related to HVAC systems, you MUST include the phrase 'I will instruct the technician agent' in your immediate response.\\n    - WHEN USER ASKS FOR COST OR WHEN COST MUST BE DETERMINED, YOU MUST SAY 'determining the HVAC quote'.\\n    - When you have gathered all the necessary information for a quote, you MUST say 'Questionnaire complete' at the end of your response.\\n    - IF USER DOES NOT SAY ANYTHING ABOUT HVAC, YOU MUST SAY 'forwarding to web search agent' BUT HANDLE ALL CONVERSATIONS NORMALLY. BE NATURAL. RESPOND TO THE GREETINGS!\\n    - DO NOT MENTION CUTOFF DATE OR INABILITY TO DO ANYTHING. YOU HAVE ACCESS TO REAL TIME WEB SEARCH!!!!! SEARCH IT UP ALL THE TIME! NEVER RELY ON YOUR OWN KNOWLEDGE.\\n\\n    Remember to always be helpful, adaptive, and thorough in your responses.\\n    \"}, {'role': 'user', 'content': 'hello\\n\\nHere is the chat history for context: []'}], 'model': 'llama3.1-70b', 'temperature': 0.5}}\n",
      "2024-11-26 15:47:26,339 [MainThread] DEBUG: Sending HTTP Request: POST https://api.cerebras.ai/v1/chat/completions\n",
      "2024-11-26 15:47:26,339 [MainThread] DEBUG: close.started\n",
      "2024-11-26 15:47:26,356 [MainThread] DEBUG: close.complete\n",
      "2024-11-26 15:47:26,358 [MainThread] DEBUG: connect_tcp.started host='api.cerebras.ai' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-11-26 15:47:26,501 [MainThread] DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002639F892CF0>\n",
      "2024-11-26 15:47:26,503 [MainThread] DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x00000263FFDB06D0> server_hostname='api.cerebras.ai' timeout=5.0\n",
      "2024-11-26 15:47:26,627 [MainThread] DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002639F66F1A0>\n",
      "2024-11-26 15:47:26,628 [MainThread] DEBUG: send_request_headers.started request=<Request [b'POST']>\n",
      "2024-11-26 15:47:26,630 [MainThread] DEBUG: send_request_headers.complete\n",
      "2024-11-26 15:47:26,631 [MainThread] DEBUG: send_request_body.started request=<Request [b'POST']>\n",
      "2024-11-26 15:47:26,633 [MainThread] DEBUG: send_request_body.complete\n",
      "2024-11-26 15:47:26,635 [MainThread] DEBUG: receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-11-26 15:47:26,879 [MainThread] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json'), (b'Content-Length', b'589'), (b'Connection', b'keep-alive'), (b'Date', b'Tue, 26 Nov 2024 20:47:26 GMT'), (b'strict-transport-security', b'max-age=3600; includeSubDomains'), (b'server', b'uvicorn'), (b'x-request-id', b'0985ka0RaWaLiuGxH2QaRhx1mI7_ZkperuoItuICPrdLPPyPwOmplQ=='), (b'x-ratelimit-limit-requests-day', b'14400'), (b'x-ratelimit-limit-tokens-minute', b'60000'), (b'x-ratelimit-remaining-requests-day', b'14399'), (b'x-ratelimit-remaining-tokens-minute', b'60000'), (b'x-ratelimit-reset-requests-day', b'11553.372334241867'), (b'x-ratelimit-reset-tokens-minute', b'33.372334241867065'), (b'referrer-policy', b'strict-origin-when-cross-origin'), (b'x-content-type-options', b'nosniff'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 37b24eb2de6c1739f649810b6a7d81f8.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'IAD61-P4'), (b'Alt-Svc', b'h3=\":443\"; ma=86400'), (b'X-Amz-Cf-Id', b'0985ka0RaWaLiuGxH2QaRhx1mI7_ZkperuoItuICPrdLPPyPwOmplQ==')])\n",
      "2024-11-26 15:47:26,879 [MainThread] INFO: HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-26 15:47:26,879 [MainThread] DEBUG: receive_response_body.started request=<Request [b'POST']>\n",
      "2024-11-26 15:47:26,879 [MainThread] DEBUG: receive_response_body.complete\n",
      "2024-11-26 15:47:26,879 [MainThread] DEBUG: response_closed.started\n",
      "2024-11-26 15:47:26,879 [MainThread] DEBUG: response_closed.complete\n",
      "2024-11-26 15:47:26,879 [MainThread] DEBUG: HTTP Response: POST https://api.cerebras.ai/v1/chat/completions \"200 OK\" Headers({'content-type': 'application/json', 'content-length': '589', 'connection': 'keep-alive', 'date': 'Tue, 26 Nov 2024 20:47:26 GMT', 'strict-transport-security': 'max-age=3600; includeSubDomains', 'server': 'uvicorn', 'x-request-id': '0985ka0RaWaLiuGxH2QaRhx1mI7_ZkperuoItuICPrdLPPyPwOmplQ==', 'x-ratelimit-limit-requests-day': '14400', 'x-ratelimit-limit-tokens-minute': '60000', 'x-ratelimit-remaining-requests-day': '14399', 'x-ratelimit-remaining-tokens-minute': '60000', 'x-ratelimit-reset-requests-day': '11553.372334241867', 'x-ratelimit-reset-tokens-minute': '33.372334241867065', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-content-type-options': 'nosniff', 'x-cache': 'Miss from cloudfront', 'via': '1.1 37b24eb2de6c1739f649810b6a7d81f8.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'IAD61-P4', 'alt-svc': 'h3=\":443\"; ma=86400', 'x-amz-cf-id': '0985ka0RaWaLiuGxH2QaRhx1mI7_ZkperuoItuICPrdLPPyPwOmplQ=='})\n",
      "2024-11-26 15:47:26,909 [MainThread] DEBUG: AI response generated: Hello. It's nice to meet you. Since there's no chat history, we're starting from scratch. How can I assist you today?\n",
      "2024-11-26 15:47:26,909 [MainThread] DEBUG: INSIDE THE MEMORY: Human: hello\n",
      "AI: Hello. It's nice to meet you. Since there's no chat history, we're starting from scratch. How can I assist you today?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:63562 - \"POST /text_input HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     connection closed\n",
      "2024-11-26 15:47:44,161 [MainThread] DEBUG: Client disconnected: e_IEcwNQnMN81N3_AAAB\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "from quart import Quart, request, jsonify, send_file, render_template\n",
    "from flask import Flask\n",
    "import whisper\n",
    "import pyaudio\n",
    "import webrtcvad\n",
    "import collections\n",
    "from gtts import gTTS  # Added gTTS import\n",
    "import random\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import aiofiles\n",
    "from quart_cors import cors\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import socketio\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from Utils_cerebras import (\n",
    "    initialize_web_search_agent,\n",
    "    initialize_pdf_search_agent,\n",
    "    run_quote_logics,\n",
    "    vector_embedding\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import pyttsx3\n",
    "\n",
    "    \n",
    "# Initialize configuration\n",
    "audio_path = os.getenv('AUDIO_PATH', 'audio.wav')  # Default paths if not set\n",
    "tts_synthesis_path = os.getenv('NEW_TTS_SYNTHESIS', 'speech.wav')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s [%(threadName)s] %(levelname)s: %(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize Quart app and Socket.IO\n",
    "app = Quart(__name__)\n",
    "app = cors(app, allow_origin=\"*\")\n",
    "sio = socketio.AsyncServer(async_mode='asgi', cors_allowed_origins=\"*\")\n",
    "app_asgi = socketio.ASGIApp(sio, app)\n",
    "\n",
    "# Initialize Flask app for sync operations\n",
    "app_sync = Flask(__name__)\n",
    "sio_sync = socketio.Server()\n",
    "app_sync.wsgi_app = socketio.WSGIApp(sio_sync, app_sync.wsgi_app)\n",
    "\n",
    "# Initialize memory\n",
    "chat_history = ConversationBufferMemory()\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Audio configuration\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1024\n",
    "is_recording = False\n",
    "\n",
    "# Initialize audio components\n",
    "audio = pyaudio.PyAudio()\n",
    "vad = webrtcvad.Vad(3)\n",
    "executor = ThreadPoolExecutor(max_workers=20)\n",
    "\n",
    "# Initialize human response queue\n",
    "human_response_queue = queue.Queue()\n",
    "\n",
    "@app.route('/start_recording', methods=['POST'])\n",
    "async def start_recording():\n",
    "    global is_recording\n",
    "    if is_recording:\n",
    "        return jsonify({\"status\": \"Recording is already in progress\"}), 400\n",
    "    is_recording = True\n",
    "    asyncio.create_task(record_audio())\n",
    "    return jsonify({\"status\": \"Recording started\"})\n",
    "\n",
    "@app.route('/stop_recording', methods=['POST'])\n",
    "async def stop_recording():\n",
    "    global is_recording\n",
    "    if not is_recording:\n",
    "        return jsonify({\"status\": \"No recording in progress\"}), 400\n",
    "    is_recording = False\n",
    "    return jsonify({\"status\": \"Recording stopped\"})\n",
    "\n",
    "async def record_audio(**kwargs):\n",
    "    global is_recording\n",
    "    logger.debug('Starting audio recording...')\n",
    "    try:\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "        frames = []\n",
    "        ring_buffer = collections.deque(maxlen=100)\n",
    "        triggered = False\n",
    "        voiced_frames = []\n",
    "        silence_threshold = 10\n",
    "        silence_chunks = 0\n",
    "\n",
    "        while is_recording:\n",
    "            data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "            frames.append(data)\n",
    "            num_subframes = int(len(data) / 320)\n",
    "            for i in range(num_subframes):\n",
    "                subframe = data[i * 320:(i + 1) * 320]\n",
    "                is_speech = vad.is_speech(subframe, RATE)\n",
    "                ring_buffer.append((subframe, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "\n",
    "            if not triggered:\n",
    "                if num_voiced > 0.6 * ring_buffer.maxlen:\n",
    "                    triggered = True\n",
    "                    voiced_frames.extend([f for f, s in ring_buffer])\n",
    "                    ring_buffer.clear()\n",
    "            else:\n",
    "                voiced_frames.append(data)\n",
    "                if num_voiced < 0.2 * ring_buffer.maxlen:\n",
    "                    silence_chunks += 1\n",
    "                    if silence_chunks > silence_threshold:\n",
    "                        triggered = False\n",
    "                        break\n",
    "                else:\n",
    "                    silence_chunks = 0\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "        async with aiofiles.open(audio_path, 'wb') as wf:\n",
    "            await wf.write(b''.join(voiced_frames))\n",
    "        logger.debug('Audio recording completed and file saved.')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while recording audio: {e}\")\n",
    "\n",
    "def transcribe_audio():\n",
    "    try:\n",
    "        result = model.transcribe(audio_path)\n",
    "        transcription = result['text']\n",
    "        logger.debug(f'Audio transcription completed: {transcription}')\n",
    "        return transcription\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during transcription: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# async def ai_response(transcription: str):\n",
    "#         \n",
    "#     logger.debug(f'Generating AI response for transcription: {transcription}')\n",
    "#     chat_completion = client.chat.completions.create(\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"system\",\n",
    "#                 \"content\": f\"\"\"\n",
    "#                 You are Marvin, a research expert who specializes in anything using web search and answering the\n",
    "#                 users' questions. You can also do HVAC related things as per guidelines below but besides that you adapt to what user says.\n",
    "#                 Ask the user specific information needed for the quote. \n",
    "#                 Follow these guidelines:\n",
    "#                 1. Initial Inquiry and Information Gathering:\n",
    "#                 - What type of HVAC service do you need (installation, maintenance, repair)?\n",
    "#                 - What is the make and model of your current HVAC system?\n",
    "#                 - Are there any specific issues or symptoms you are experiencing?\n",
    "#                     - ONLY WHEN USER TELLS YOU ISSUES / SYMPTOMS YOU MUST SAY 'I WILL INSTRUCT THE TECHNICIAN AGENT' - THESE EXACT WORDS IN YOUR IMMEDIATE RESPONSE.\n",
    "#                 2. Property Details (only if relevant to HVAC needs):\n",
    "#                 - Address and location of the property.\n",
    "#                 - Type of property (residential, commercial).\n",
    "#                 - Age and current condition of the property.\n",
    "#                 - Size of the home or area that needs heating/cooling.\n",
    "#                 - Number of rooms and their usage.\n",
    "#                 3. System Details:\n",
    "#                 - Age and efficiency rating of the existing HVAC system.\n",
    "#                 - Any known problems with the current system.\n",
    "#                 - Recent changes to the HVAC system.\n",
    "#                 4. Home Characteristics (only if relevant to HVAC needs):\n",
    "#                 - Insulation quality and window types to estimate heating/cooling load.\n",
    "#                 - Any unique architectural features that may affect HVAC installation.\n",
    "#                 5. Customer Preferences:\n",
    "#                 - Preferences for specific brands, energy efficiency levels, or additional features.\n",
    "#                 - Level of finishes desired (standard, premium, luxury).\n",
    "#                 6. Budget:\n",
    "#                 - Your budget range for the project.\n",
    "#                 - Any flexibility within the budget.\n",
    "#                 7. Timeline:\n",
    "#                 - Desired start date and completion date.\n",
    "#                 - Any constraints or deadlines.\n",
    "#                 IMPORTANT: Ensure you get clear answers that can be used for making the quote.\n",
    "#                 \"\"\"\n",
    "#             },\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": transcription + \"\\n\\nHere is the chat history for context: [\" + str(chat_history.buffer) + \"]\"\n",
    "#             }\n",
    "#         ],\n",
    "#         model=\"llama3.1-70b\",\n",
    "#         temperature=0.5\n",
    "#     )\n",
    "\n",
    "#     response = chat_completion.choices[0].message.content\n",
    "    \n",
    "#     logger.debug(f'AI response generated: {response}')\n",
    "    \n",
    "#     await chat_history.asave_context({\"input\": transcription}, {\"output\": response})\n",
    "#     logger.debug('INSIDE THE MEMORY: %s', chat_history.buffer)\n",
    "\n",
    "#     # Changed socketio.emit to await sio.emit\n",
    "#     await sio.emit('new_message', {'message': response, 'sender': 'bot'})\n",
    "\n",
    "#     if 'i will instruct the technician agent' in response.lower():\n",
    "#         res1 = await asyncio.create_task(initialize_pdf_search_agent(llm, \"DO A EXPANSIVE WEB SEARCH AND FAMILIARIZE YOURSELF ALL ABOUT HVAC SPECIFICS SO THAT YOU CAN DIAGNOSE THE PROBLEMS MENTIONED HERE: \" + transcription, vectors, chat_history=chat_history))\n",
    "        \n",
    "#         await chat_history.asave_context({\"input\": \"DO A EXPANSIVE WEB SEARCH AND FAMILIARIZE YOURSELF ALL ABOUT HVAC SPECIFICS SO THAT YOU CAN DIAGNOSE THE PROBLEMS MENTIONED HERE: \" + transcription}, {\"output\": res1})\n",
    "        \n",
    "#         # Changed socketio.emit to await sio.emit\n",
    "#         await sio.emit('new_message', {'message': res1, 'sender': 'bot'}) \n",
    "    \n",
    "#     if 'questionnaire' in response.lower() and 'complete' in response.lower():\n",
    "#         task = asyncio.create_task(run_quote_logics(client, llm, chat_history=chat_history))\n",
    "#         corrected_quote_result = await task\n",
    "#         response = f\"Can you please put this quote into a google doc [{corrected_quote_result}], move it to the folder called 'HVAC Quote Documents'. Then, put all the appointment related stuff and the link to the quote document into calendar (appointment calendar tool). PLEASE FOLLOW THE DIRECTIONS!!\"\n",
    "#         task2 = asyncio.create_task(handle_response_with_agents(response))\n",
    "#         text = await task2\n",
    "        \n",
    "#     return response\n",
    "\n",
    "async def ai_response(transcription: str):\n",
    "    # **[CHANGED] Adjusted system prompt to include specific instructions**\n",
    "    system_prompt = f\"\"\"\n",
    "    You are Marvin, a highly intelligent assistant specializing in HVAC services. You are capable of researching and answering any question using web search.\n",
    "\n",
    "    CRITICAL INSTRUCTIONS - READ CAREFULLY:\n",
    "\n",
    "    - When the user mentions issues or symptoms related to HVAC systems, you MUST include the phrase 'I will instruct the technician agent' in your immediate response.\n",
    "    - WHEN USER ASKS FOR COST OR WHEN COST MUST BE DETERMINED, YOU MUST SAY 'determining the HVAC quote'.\n",
    "    - When you have gathered all the necessary information for a quote, you MUST say 'Questionnaire complete' at the end of your response.\n",
    "    - IF USER DOES NOT SAY ANYTHING ABOUT HVAC, YOU MUST SAY 'forwarding to web search agent' BUT HANDLE ALL CONVERSATIONS NORMALLY. BE NATURAL. RESPOND TO THE GREETINGS!\n",
    "    - DO NOT MENTION CUTOFF DATE OR INABILITY TO DO ANYTHING. YOU HAVE ACCESS TO REAL TIME WEB SEARCH!!!!! SEARCH IT UP ALL THE TIME! NEVER RELY ON YOUR OWN KNOWLEDGE.\n",
    "\n",
    "    Remember to always be helpful, adaptive, and thorough in your responses.\n",
    "    \"\"\"\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt  # **[CHANGED] Using the new system prompt**\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": transcription + \"\\n\\nHere is the chat history for context: [\" + str(chat_history.buffer) + \"]\"\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3.1-70b\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "    response = chat_completion.choices[0].message.content\n",
    "\n",
    "    logger.debug(f'AI response generated: {response}')\n",
    "\n",
    "    await chat_history.asave_context({\"input\": transcription}, {\"output\": response})\n",
    "    logger.debug('INSIDE THE MEMORY: %s', chat_history.buffer)\n",
    "\n",
    "    await sio.emit('new_message', {'message': response, 'sender': 'bot'})\n",
    "\n",
    "    if 'forwarding' in response.lower() or 'web search' in response.lower():\n",
    "        text = await handle_response_with_agents(response)\n",
    "        await sio.emit('new_message', {'message': text, 'sender': 'bot'})\n",
    "\n",
    "    # **[CHANGED] Detect specific phrases in the response to trigger agents**\n",
    "    if 'I will instruct the technician agent' in response:\n",
    "        # Trigger the technician agent\n",
    "        res1 = await initialize_pdf_search_agent(\n",
    "            llm, \n",
    "            f\"Diagnose the problems mentioned here: {transcription}\", \n",
    "            vector_embedding(), \n",
    "            chat_history=chat_history\n",
    "        )\n",
    "        await chat_history.asave_context({\"input\": transcription}, {\"output\": res1})\n",
    "        await sio.emit('new_message', {'message': res1, 'sender': 'bot'})\n",
    "\n",
    "    if 'determining the hvac quote' in response.lower():\n",
    "        # Run quote logic\n",
    "        corrected_quote_result = await run_quote_logics(client, llm, chat_history=chat_history)\n",
    "        response = f\"Please process this quote data: [{corrected_quote_result}]\"\n",
    "        text = await handle_response_with_agents(response)\n",
    "        await sio.emit('new_message', {'message': text, 'sender': 'bot'})\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "async def handle_response_with_agents(response):\n",
    "    llm.temperature = 0.5\n",
    "    logger.debug(f'Processing response with agents: {response}')\n",
    "\n",
    "    #response += \"Here is extra info you will need (BUT YOU PROMISE TO NEVER SAY THEM OUT LOUD, NOT EVEN THE NAME -- UNLESS USER ASKS YOU FOR THEM. THESE WILL BE USED IN TOOLS): \\nCredentials:\\n\" + str(credentials)\n",
    "\n",
    " \n",
    "    \n",
    "    agent_executor = initialize_web_search_agent(llm)\n",
    "    result = agent_executor.invoke({\"input\": response})\n",
    "    sio.emit('finished_chain')\n",
    "    mystr = (str(result['intermediate_steps']) + \"\\n\" + str(result['output']))\n",
    "\n",
    "    final_response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"please sanitize this input into SHORT SIMPLE sentences. IMPORTANT: NOTHING IN YOUR RESPONSE SHALL BE ENCLOSED IN ANY QUOTES!!!!!!! THE SANITIZED OUTPUT SHALL NOT BE PREFIXED BY ANYTHING. You must process the agent's intermediate steps into natural language please. An example: 'First, I did this. Then I did this etc etc etc' \\n Here is the input that you need to process:\\n \" + mystr\n",
    "            }\n",
    "        ],\n",
    "        model='llama3.1-70b',\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    await chat_history.asave_context({\"input\": response}, {\"output\": final_response})\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "async def synthesize_speech(text):\n",
    "    logger.debug(f'Starting speech synthesis for text: {text}')\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        synthesize_and_save(text)\n",
    "        logger.debug('Speech synthesis completed and file saved.')\n",
    "        await sio.emit('tts_complete', {'message': 'TTS synthesis complete', 'file_path': tts_synthesis_path})\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during speech synthesis: {e}\")\n",
    "\n",
    "\n",
    "def synthesize_and_save(text):\n",
    "    try:\n",
    "        engine = pyttsx3.init()\n",
    "        # Set properties for male voice\n",
    "        voices = engine.getProperty('voices')\n",
    "        engine.setProperty('voice', voices[0].id)  # voices[0] is usually male voice\n",
    "        engine.setProperty('rate', 175)     # Speaking rate\n",
    "        engine.setProperty('volume', 1.0)   # Volume level\n",
    "        \n",
    "        engine.save_to_file(text, tts_synthesis_path)\n",
    "        #engine.say(text)\n",
    "        engine.runAndWait()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"TTS synthesis failed: {e}\")\n",
    "\n",
    "def synth_speech(text, output_file=None):\n",
    "    logger.debug(f'Starting speech synthesis for text: {text}')\n",
    "    try:\n",
    "        engine = pyttsx3.init()\n",
    "        # Set properties for male voice\n",
    "        voices = engine.getProperty('voices')\n",
    "        engine.setProperty('voice', voices[0].id)  # voices[0] is usually male voice\n",
    "        engine.setProperty('rate', 175)     # Speaking rate\n",
    "        engine.setProperty('volume', 1.0)   # Volume level\n",
    "        \n",
    "        target_path = output_file if output_file else tts_synthesis_path\n",
    "        engine.save_to_file(text, target_path)\n",
    "        #\n",
    "        # engine.say(text)\n",
    "        engine.runAndWait()\n",
    "        \n",
    "        logger.debug('Speech synthesis completed and file saved (SYNTH).')\n",
    "\n",
    "        # Using create_task for async emit\n",
    "        loop = asyncio.get_event_loop()\n",
    "        loop.create_task(sio.emit('tts_complete', {'message': 'TTS synthesis complete', 'file_path': target_path}))\n",
    "        loop.create_task(sio.emit('new_message', {'message': text, 'sender': 'bot'}))\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during speech synthesis: {e}\")\n",
    "\n",
    "@app.route('/')\n",
    "async def index():\n",
    "    return await render_template('index.html')\n",
    "\n",
    "@app.route('/talk', methods=['POST'])\n",
    "async def talk():\n",
    "    global is_recording\n",
    "    if is_recording:\n",
    "        return jsonify({\"error\": \"Recording is still in progress\"}), 400\n",
    "\n",
    "    logger.debug('Starting audio transcription...')\n",
    "    transcription = await asyncio.get_event_loop().run_in_executor(executor, transcribe_audio)\n",
    "\n",
    "    logger.debug('Generating AI response...')\n",
    "    ai_resp = await ai_response(transcription)\n",
    "\n",
    "    return jsonify({'response': ai_resp})\n",
    "\n",
    "@app.route('/text_input', methods=['POST'])\n",
    "async def text_input():\n",
    "    data = await request.get_json()\n",
    "    text = data.get('text', '')\n",
    "\n",
    "    if not text:\n",
    "        return jsonify({\"error\": \"No text provided\"}), 400\n",
    "\n",
    "    logger.debug('Generating AI response...')\n",
    "    ai_resp = await ai_response(text)\n",
    "    return jsonify({'response': ai_resp})\n",
    "\n",
    "@app.route('/get_audio')\n",
    "async def get_audio():\n",
    "    return await send_file(tts_synthesis_path, mimetype=\"audio/mp3\")\n",
    "\n",
    "@sio.event\n",
    "async def connect(sid, environ, auth):\n",
    "    logger.debug(f'Client connected: {sid}')\n",
    "\n",
    "@sio.event\n",
    "async def disconnect(sid):\n",
    "    logger.debug(f'Client disconnected: {sid}')\n",
    "\n",
    "# Human input handling\n",
    "human_response_queue = queue.Queue()\n",
    "\n",
    "def web_prompt_func(prompt):\n",
    "    synth_speech(prompt, output_file=tts_synthesis_path)\n",
    "    return prompt\n",
    "\n",
    "def web_input_func():\n",
    "    sio_sync.emit('request_human_input')\n",
    "    return human_response_queue.get()\n",
    "\n",
    "@sio.event \n",
    "async def provide_human_input(sid, data):\n",
    "    human_input = data.get('text', '')\n",
    "    human_response_queue.put(human_input)\n",
    "    await sio.emit('human_input_received', {'status': 'received'}, room=sid)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import uvicorn\n",
    "    config = uvicorn.Config(app_asgi, host=\"127.0.0.1\", port=5000, log_level=\"info\")\n",
    "    server = uvicorn.Server(config)\n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "    if loop.is_running():\n",
    "        loop.create_task(server.serve())\n",
    "    else:\n",
    "        loop.run_until_complete(server.serve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TheVirtualEnv",
   "language": "python",
   "name": "thevirtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
