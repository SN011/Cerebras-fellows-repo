{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbYOAxVclp6O"
   },
   "source": [
    "# 01. Learning LangGraph - Agent Executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yS-Jzh_a_eI"
   },
   "source": [
    "modified from https://github.com/langchain-ai/langgraph/blob/main/examples/agent_executor/base.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "guac0Zh7Gz4Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv('LANGSMITH_API_KEY')\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph_01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zHfhDLnHUhU"
   },
   "source": [
    "## Making the GraphState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0Bz48n-NHOXa"
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "   # The input string\n",
    "   input: str\n",
    "   # The list of previous messages in the conversation\n",
    "   chat_history: list[BaseMessage]\n",
    "   # The outcome of a given call to the agent\n",
    "   # Needs `None` as a valid type, since this is what this will start as\n",
    "   agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "   # List of actions and corresponding observations\n",
    "   # Here we annotate this with `operator.add` to indicate that operations to\n",
    "   # this state should be ADDED to the existing values (not overwrite it)\n",
    "   intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjkCAE7ZJjdc"
   },
   "source": [
    "## Custom Tools\n",
    "\n",
    "**Tools**  \n",
    "\n",
    "Tools are interfaces that an agent can use to interact with the world. They combine a few things:\n",
    "\n",
    "\n",
    "\n",
    "1.   The name of the tool\n",
    "2.   A description of what the tool is\n",
    "3.   JSON schema of what the inputs to the tool are\n",
    "4.   The function to call\n",
    "\n",
    "\n",
    "Whether the result of a tool should be returned directly to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZBjb2RGpK8jY"
   },
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OLeIVeaEJltj"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "@tool(\"lower_case\", return_direct=True)\n",
    "def to_lower_case(input:str) -> str:\n",
    "  \"\"\"Returns the input as all lower case.\"\"\"\n",
    "  return input.lower()\n",
    "\n",
    "@tool(\"random_number\", return_direct=True)\n",
    "def random_number_maker(input:str) -> str:\n",
    "    \"\"\"Returns a random number between 0-100.\"\"\"\n",
    "    return random.randint(0, 100)\n",
    "\n",
    "tools = [to_lower_case,random_number_maker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnqHbU-3LSe_",
    "outputId": "ea9f2a6f-6ee0-4dcd-d033-1bb1048f0634"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: Connection error caused failure to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. Please confirm your internet connection. ConnectTimeout(MaxRetryError(\"HTTPSConnectionPool(host='api.smith.langchain.com', port=443): Max retries exceeded with url: /runs/multipart (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000017933344F80>, 'Connection to api.smith.langchain.com timed out. (connect timeout=10.0)'))\"))\n",
      "Content-Length: 61913\n",
      "API Key: lsv2_********************************************cetrace=c295db05-00b7-42f1-94d9-82508e932889,id=9efd3a66-5197-407f-ad9a-e99a716794d9; trace=c295db05-00b7-42f1-94d9-82508e932889,id=32d0f848-7650-4c76-a4f3-7605accfb9c7; trace=c295db05-00b7-42f1-94d9-82508e932889,id=91740052-b31c-4c87-abbb-83978cf6f23d; trace=c295db05-00b7-42f1-94d9-82508e932889,id=6e2f72a3-2048-46b1-8421-b98de503e9a4; trace=c295db05-00b7-42f1-94d9-82508e932889,id=2b58a5ac-de8b-45c5-811d-d4b19493ed9a; trace=c295db05-00b7-42f1-94d9-82508e932889,id=77b7255e-b7c2-4186-81fc-0dd688995537; trace=c295db05-00b7-42f1-94d9-82508e932889,id=3a365abb-b75d-4bb7-834c-6fdeeaf05140; trace=c295db05-00b7-42f1-94d9-82508e932889,id=4a7c5103-31ad-4165-8e27-015b58681101; trace=c295db05-00b7-42f1-94d9-82508e932889,id=e4eda4bd-c107-437a-ab51-dc0d2453d69d; trace=c295db05-00b7-42f1-94d9-82508e932889,id=c036c3e6-2895-4dfe-b7bf-a57f2df729b7; trace=c295db05-00b7-42f1-94d9-82508e932889,id=ab81a367-3b1f-42a6-8195-73e13d78a409; trace=c295db05-00b7-42f1-94d9-82508e932889,id=402d25b3-b87a-4f3d-8780-2fc043064f50; trace=c295db05-00b7-42f1-94d9-82508e932889,id=e9f82e3a-5396-4ed1-9a03-d93fabec2884; trace=c295db05-00b7-42f1-94d9-82508e932889,id=631dfa6f-89d9-4a05-948c-2a21cdbb536e; trace=c295db05-00b7-42f1-94d9-82508e932889,id=0a93ea90-7c47-4a38-8180-0331495c7bbc; trace=c295db05-00b7-42f1-94d9-82508e932889,id=4bea526a-00fb-4d7d-9892-ab878687c4b4\n",
      "Failed to multipart ingest runs: Connection error caused failure to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. Please confirm your internet connection. ConnectTimeout(MaxRetryError(\"HTTPSConnectionPool(host='api.smith.langchain.com', port=443): Max retries exceeded with url: /runs/multipart (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000017933344F80>, 'Connection to api.smith.langchain.com timed out. (connect timeout=10.0)'))\"))\n",
      "Content-Length: 195435\n",
      "API Key: lsv2_********************************************cetrace=c295db05-00b7-42f1-94d9-82508e932889,id=7126cdfd-13b6-411c-a890-6b0571e9b941; trace=c295db05-00b7-42f1-94d9-82508e932889,id=a5886dbe-f5fa-412a-89d6-449535270f77; trace=c295db05-00b7-42f1-94d9-82508e932889,id=b9618d5c-5ae6-475d-a0e9-297856c9b02c; trace=41134676-1d87-4e91-bc49-3523550927d0,id=41134676-1d87-4e91-bc49-3523550927d0; trace=41134676-1d87-4e91-bc49-3523550927d0,id=13306ac2-48fc-490f-a74b-450743666876; trace=41134676-1d87-4e91-bc49-3523550927d0,id=442bf25d-a1db-4c34-9b72-b25f2d824169; trace=41134676-1d87-4e91-bc49-3523550927d0,id=75012f23-d00c-4c57-af34-610a59dbb760; trace=41134676-1d87-4e91-bc49-3523550927d0,id=144c03bf-e1fc-4c03-9b5a-edec19e56997; trace=41134676-1d87-4e91-bc49-3523550927d0,id=46bec973-5cf4-411f-86aa-4eb6786e7aa2; trace=41134676-1d87-4e91-bc49-3523550927d0,id=af8fa8c0-2789-4209-984f-9352fed10ce0; trace=41134676-1d87-4e91-bc49-3523550927d0,id=cdb7c9f5-758c-41d8-a743-3ec7f90ac25a; trace=41134676-1d87-4e91-bc49-3523550927d0,id=ce0e1886-29a5-4c00-8bd4-e691c0537583; trace=e9b81563-42d8-45ab-9a68-2f1444f867fa,id=e9b81563-42d8-45ab-9a68-2f1444f867fa; trace=e9b81563-42d8-45ab-9a68-2f1444f867fa,id=573734de-9cb4-45b8-970e-405a460a3f80; trace=e9b81563-42d8-45ab-9a68-2f1444f867fa,id=2a2fb4d2-3237-4908-9fd9-3dcf5e9f6b89; trace=e9b81563-42d8-45ab-9a68-2f1444f867fa,id=93cad975-0f8f-4f42-ae41-dfb3a0a2355f; trace=e9b81563-42d8-45ab-9a68-2f1444f867fa,id=be28e561-e456-44c1-94bc-b0d9bac4fccf; trace=e9b81563-42d8-45ab-9a68-2f1444f867fa,id=f1ab5aea-2fdd-491b-90fc-0462853d1f64; trace=e9b81563-42d8-45ab-9a68-2f1444f867fa,id=d415a3ce-ee63-4499-87a5-5f846db2bb09; trace=e9b81563-42d8-45ab-9a68-2f1444f867fa,id=670e155d-bd1c-4d06-9637-83f76ee7d8d3; trace=e9b81563-42d8-45ab-9a68-2f1444f867fa,id=9f948aab-2113-495a-b212-e5140a4e16ed; trace=c1d6779f-a325-432c-b1ee-619c91e0c6f6,id=c1d6779f-a325-432c-b1ee-619c91e0c6f6; trace=c1d6779f-a325-432c-b1ee-619c91e0c6f6,id=465dc365-7f75-4551-a27e-20e69454941b; trace=c1d6779f-a325-432c-b1ee-619c91e0c6f6,id=d63dc700-0062-4088-8b08-6bbba6ae66e2; trace=c1d6779f-a325-432c-b1ee-619c91e0c6f6,id=05a8ce7a-63d8-4d32-be55-f610571275ce; trace=c1d6779f-a325-432c-b1ee-619c91e0c6f6,id=5e74753a-b157-4914-a63b-6bab40cdb720; trace=c1d6779f-a325-432c-b1ee-619c91e0c6f6,id=a329988a-a340-4709-a387-98954c53cf7a; trace=c1d6779f-a325-432c-b1ee-619c91e0c6f6,id=b905f74c-0922-4114-adb4-d6ac44833993; trace=c1d6779f-a325-432c-b1ee-619c91e0c6f6,id=f6d6a887-493d-4839-849d-375e4d9a3d9b; trace=c1d6779f-a325-432c-b1ee-619c91e0c6f6,id=9ad7457a-f01a-447c-818b-282ead690317; trace=c295db05-00b7-42f1-94d9-82508e932889,id=c295db05-00b7-42f1-94d9-82508e932889; trace=c295db05-00b7-42f1-94d9-82508e932889,id=3a365abb-b75d-4bb7-834c-6fdeeaf05140; trace=c295db05-00b7-42f1-94d9-82508e932889,id=4a7c5103-31ad-4165-8e27-015b58681101; trace=c295db05-00b7-42f1-94d9-82508e932889,id=e9f82e3a-5396-4ed1-9a03-d93fabec2884\n"
     ]
    }
   ],
   "source": [
    "random_number_maker.run('random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8X4Es0EJaYb7",
    "outputId": "f954ca4a-e43b-4609-c158-22d47f9ed159"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sam'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_lower_case.run('SAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSl1IkYEqTKx"
   },
   "source": [
    "## Agent - with new create_open_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZRfmuHYoqR-H"
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_structured_chat_agent\n",
    "from tools.initialize_cerebras import init_cerebras\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "client, llm = init_cerebras()\n",
    "\n",
    "# Construct the OpenAI Functions agent\n",
    "agent_runnable = create_structured_chat_agent(llm,\n",
    "                                               tools,\n",
    "                                               prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YitzfHjZq4bv",
    "outputId": "83df8a9d-ffdd-4dea-fb9c-1defc36ca76d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000017914A97740>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'structured-chat-agent', 'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tool_names', 'tools'], input_types={}, partial_variables={}, template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\n{tools}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or {tool_names}\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={}, template='{input}\\n\\n{agent_scratchpad}\\n (reminder to respond in a JSON blob no matter what)'), additional_kwargs={})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "enowMbGUwEXb",
    "outputId": "d71298f0-6249-43d5-d765-a983f55c83c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatPromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000017914A97740>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'structured-chat-agent', 'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tool_names', 'tools'], input_types={}, partial_variables={}, template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\n{tools}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or {tool_names}\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={}, template='{input}\\n\\n{agent_scratchpad}\\n (reminder to respond in a JSON blob no matter what)'), additional_kwargs={})])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GJ7_ezEUvpjv"
   },
   "outputs": [],
   "source": [
    "inputs = {\"input\": \"give me a random number and then write in words and make it lower case.\",\n",
    "          \"chat_history\": [],\n",
    "          \"intermediate_steps\":[]}\n",
    "\n",
    "agent_outcome = agent_runnable.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xVco6-WmB1ll",
    "outputId": "dfdef23b-69c7-4b66-ce26-7bab916e2970"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentAction(tool='random_number', tool_input='generate a number', log='Thought: I need to generate a random number first.\\nAction:\\n```\\n{\\n  \"action\": \"random_number\",\\n  \"action_input\": \"generate a number\"\\n}\\n```')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ux7k8XD0B90p",
    "outputId": "081af95c-70de-48d6-f7be-4ea4481d00c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(agent_runnable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEgS5eK_HdvK"
   },
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9gmzMROGHqeN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ncvn\\AppData\\Local\\Temp\\ipykernel_3756\\2882498864.py:4: LangGraphDeprecationWarning: ToolExecutor is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  tool_executor = ToolExecutor(tools)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.agents import AgentFinish\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
    "\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "JyRrGocuHZ2b"
   },
   "outputs": [],
   "source": [
    "# Define the agent/graph\n",
    "def run_agent(data):\n",
    "    agent_outcome = agent_runnable.invoke(data)\n",
    "    return {\"agent_outcome\": agent_outcome}\n",
    "\n",
    "# Define the function to execute tools\n",
    "def execute_tools(data):\n",
    "    # Get the most recent agent_outcome - this is the key added in the `agent` above\n",
    "    agent_action = data['agent_outcome']\n",
    "    # Execute the tool\n",
    "    output = tool_executor.invoke(agent_action)\n",
    "    print(f\"The agent action is {agent_action}\")\n",
    "    print(f\"The tool result is: {output}\")\n",
    "    # Return the output\n",
    "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
    "\n",
    "# Define logic that will be used to determine which conditional edge to go down\n",
    "def should_continue(data):\n",
    "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    if isinstance(data['agent_outcome'], AgentFinish):\n",
    "        return \"end\"\n",
    "    # Otherwise, an AgentAction is returned\n",
    "    # Here we return `continue` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SatNeMOsIWLx"
   },
   "source": [
    "## Define the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "tAG5MVUxIXr_"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", run_agent)\n",
    "workflow.add_node(\"action\", execute_tools)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge('action', 'agent')\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NP7CPbYyDS_q",
    "outputId": "a87ebdd5-f252-4440-8990-8e7b63164d0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'agent': {'should_continue': Branch(path=should_continue(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), ends={'continue': 'action', 'end': '__end__'}, then=None)}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HmdeWSiVDcLC",
    "outputId": "f197500a-9687-4d76-a306-c40a1f5bea73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'agent': StateNodeSpec(runnable=agent(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), metadata=None, input=<class '__main__.AgentState'>, retry_policy=None, ends=()),\n",
       "  'action': StateNodeSpec(runnable=action(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), metadata=None, input=<class '__main__.AgentState'>, retry_policy=None, ends=())},\n",
       " {('__start__', 'agent'), ('action', 'agent')})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.nodes, workflow.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JVfXfUtID0r7",
    "outputId": "634c8e3e-8975-4478-ebf7-8957524eb6cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': <langgraph.channels.last_value.LastValue at 0x179330a30c0>,\n",
       " 'chat_history': <langgraph.channels.last_value.LastValue at 0x179330a3080>,\n",
       " 'agent_outcome': <langgraph.channels.last_value.LastValue at 0x17932dcd680>,\n",
       " 'intermediate_steps': <langgraph.channels.binop.BinaryOperatorAggregate at 0x17932fe0f80>}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.channels #['intermediate_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qr_c40yBpr4f",
    "outputId": "c5838f2a-5381-4444-fe70-11aa06edfbd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentAction(tool='random_number', tool_input='Give me a random number', log='Thought: To give you a random number, I should use the random_number tool. \\n\\nAction:\\n```\\n{\\n  \"action\": \"random_number\",\\n  \"action_input\": \"Give me a random number\"\\n}\\n```')}\n",
      "----\n",
      "The agent action is tool='random_number' tool_input='Give me a random number' log='Thought: To give you a random number, I should use the random_number tool. \\n\\nAction:\\n```\\n{\\n  \"action\": \"random_number\",\\n  \"action_input\": \"Give me a random number\"\\n}\\n```'\n",
      "The tool result is: 49\n",
      "{'intermediate_steps': [(AgentAction(tool='random_number', tool_input='Give me a random number', log='Thought: To give you a random number, I should use the random_number tool. \\n\\nAction:\\n```\\n{\\n  \"action\": \"random_number\",\\n  \"action_input\": \"Give me a random number\"\\n}\\n```'), '49')]}\n",
      "----\n",
      "{'agent_outcome': AgentAction(tool='lower_case', tool_input='Forty-nine', log='To write the number in words and make it lower case, I will first convert the number to words and then use the lower_case tool.\\n\\nAction:\\n```\\n{\\n  \"action\": \"lower_case\",\\n  \"action_input\": \"Forty-nine\"\\n}\\n```')}\n",
      "----\n",
      "The agent action is tool='lower_case' tool_input='Forty-nine' log='To write the number in words and make it lower case, I will first convert the number to words and then use the lower_case tool.\\n\\nAction:\\n```\\n{\\n  \"action\": \"lower_case\",\\n  \"action_input\": \"Forty-nine\"\\n}\\n```'\n",
      "The tool result is: forty-nine\n",
      "{'intermediate_steps': [(AgentAction(tool='lower_case', tool_input='Forty-nine', log='To write the number in words and make it lower case, I will first convert the number to words and then use the lower_case tool.\\n\\nAction:\\n```\\n{\\n  \"action\": \"lower_case\",\\n  \"action_input\": \"Forty-nine\"\\n}\\n```'), 'forty-nine')]}\n",
      "----\n",
      "{'agent_outcome': AgentFinish(return_values={'output': 'Your random number is 49, which is forty-nine in words, and here it is in lower case: forty-nine.'}, log='Your random number is 49, which is forty-nine in words, and here it is in lower case: forty-nine. \\n\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Your random number is 49, which is forty-nine in words, and here it is in lower case: forty-nine.\"\\n}\\n```')}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"give me a random number and then write in words and make it lower case.\", \"chat_history\": []}\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGT9kXywqJGM",
    "outputId": "c6cd9ead-3a96-401e-e1b2-8c88008b218a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The agent action is tool='random_number' tool_input='random' log='Action:\\n```\\n{\\n  \"action\": \"random_number\",\\n  \"action_input\": \"random\"\\n}\\n```'\n",
      "The tool result is: 62\n",
      "The agent action is tool='lower_case' tool_input='sixty-two' log='To write the number in words and make it lower case, I can first write the number in words and then convert it to lower case.\\n\\nAction:\\n```\\n{\\n  \"action\": \"lower_case\",\\n  \"action_input\": \"sixty-two\"\\n}\\n```'\n",
      "The tool result is: sixty-two\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"give me a random number and then write in words and make it lower case\", \"chat_history\": []}\n",
    "\n",
    "output = app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-YfntCeAuOPG",
    "outputId": "e9982d57-3036-4d0d-baf4-f4718d59a677"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i have a random number, wrote it in words, and made it lower case. the number is sixty-two.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.get(\"agent_outcome\").return_values['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErubbyceuOPH",
    "outputId": "d3bb7472-efed-4092-8daa-473c5fceaaf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(AgentAction(tool='random_number', tool_input='random', log='Action:\\n```\\n{\\n  \"action\": \"random_number\",\\n  \"action_input\": \"random\"\\n}\\n```'),\n",
       "  '62'),\n",
       " (AgentAction(tool='lower_case', tool_input='sixty-two', log='To write the number in words and make it lower case, I can first write the number in words and then convert it to lower case.\\n\\nAction:\\n```\\n{\\n  \"action\": \"lower_case\",\\n  \"action_input\": \"sixty-two\"\\n}\\n```'),\n",
       "  'sixty-two')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.get(\"intermediate_steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "_mSFW-4Crpyd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The agent action is tool='lower_case' tool_input='Is it cold in San Francisco in January?' log='Thought: To determine if it gets cold in San Francisco in January, we should consider the typical winter weather in the area. However, the question doesn\\'t explicitly ask for a direct answer, so I\\'ll provide one by rephrasing it.\\n\\nAction:\\n```\\n{\\n  \"action\": \"lower_case\",\\n  \"action_input\": \"Is it cold in San Francisco in January?\"\\n}\\n```'\n",
      "The tool result is: is it cold in san francisco in january?\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"does it get cold in SF in Jan?\", \"chat_history\": []}\n",
    "\n",
    "output = app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "yd88Rrmftqa3",
    "outputId": "c5b4725f-dab4-4399-9100-07fd51084ceb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, it can get quite chilly in San Francisco in January, with average temperatures ranging from 45째F to 57째F (7째C to 14째C).'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.get(\"agent_outcome\").return_values['output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4HwY9Ept0c2",
    "outputId": "d9c4db24-5dd1-4451-e08d-f68660293da9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(AgentAction(tool='lower_case', tool_input='Is it cold in San Francisco in January?', log='Thought: To determine if it gets cold in San Francisco in January, we should consider the typical winter weather in the area. However, the question doesn\\'t explicitly ask for a direct answer, so I\\'ll provide one by rephrasing it.\\n\\nAction:\\n```\\n{\\n  \"action\": \"lower_case\",\\n  \"action_input\": \"Is it cold in San Francisco in January?\"\\n}\\n```'),\n",
       "  'is it cold in san francisco in january?')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.get(\"intermediate_steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9ri9QQ5ui_X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TheVirtualEnv",
   "language": "python",
   "name": "thevirtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
